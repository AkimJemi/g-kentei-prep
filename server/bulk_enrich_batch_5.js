import pkg from 'pg';
const { Pool } = pkg;

const connectionString = 'postgresql://g_kentei_prep_app_db_user:0vZFHekJvsuMexPcBCKx5Ix4Noy7WZJO@dpg-d63nv6cr85hc73bckig0-a.oregon-postgres.render.com/g_kentei_prep_app_db';
const pool = new Pool({
  connectionString,
  ssl: { rejectUnauthorized: false }
});

const enrichment = {
    101: ["画像の各部分を同じ重みで処理する「重み共有」と、近くのピクセルだけを見る「局所受容野」がパラメータ削減の理由です。", "画像サイズを縮小する処理であり、パラメータ削減の主因は重み共有です。", "過学習を防ぐためにニューロンをランダムに無効化する手法です。", "学習を安定化・高速化するための正規化手法です。"],
    102: ["新しい情報をセル状態にどれだけ加えるかを決めるのは「入力ゲート(Input Gate)」です。", "LSTMにおいて、過去の記憶（セル状態）をどれだけ保持・忘却するかを制御するゲートです。", "セル状態から次の隠れ状態として何を出力するかを決めるのは「出力ゲート」です。", "GRUはLSTMを簡素化したモデルであり、別のアーキテクチャの用語です。"],
    103: ["単語を意味的な近さを反映した高次元の数値ベクトルに変換する技術（Word2Vecなど）です。", "文を意味を持つ最小単位（形態素）に分割する処理は「形態素解析」です。", "文の構造や修飾関係を解析するのは「構文解析」です。", "表記のばらつきを統一する前処理は「正規化」です。"],
    104: ["RNNやCNNを使わず、注意機構（Attention）のみで構成された自然言語処理の革新的なモデルです。", "Transformerのエンコーダ部分を用いたモデルはBERT（2018年発表）です。", "スキップ接続を用いた画像認識モデルはResNetです。", "時系列データを扱う再帰的モデルはRNNです。"],
    105: ["左から右へ単方向で予測する言語モデルで、GPTなどがこれに該当します。", "文脈を前後（双方向）から読み取ることで、文章の意味を深く理解できるモデルです。", "Text-to-Text Transfer TransformerはT5のことです。", "次世代モデルには様々なものがありますが、双方向モデルの代表例はBERTです。"],
    106: ["Retreival-Augmented Generation。外部データベースから関連情報を検索し、それを根拠に回答を生成する手法です。", "既存のモデルを追加学習させる手法はファインチューニングです。", "AIに悪意のある指示を与えて制限を突破させる攻撃はプロンプトインジェクション等です。", "大きなモデルの知識を小さなモデルに移すのは知識蒸留です。"],
    107: ["Text-to-Speech。テキストから音声を生成する技術です。", "Automatic Speech Recognition。人間の音声をテキストに変換する技術です。", "テキスト生成はNLG（Natural Language Generation）等と呼ばれます。", "ユーザーの意図を解釈するのはNLU（Natural Language Understanding）です。"],
    108: ["単語の意味を数値化したベクトル表現です。", "言語モデルが処理するテキストの最小単位（単語や文字の断片）です。", "ユーザーがAIへ入力する指示文です。", "コンテキストはLLMの入力の文脈を指します。"],
    109: ["AI（特にLLM）から望ましい出力を得るために、指示（プロンプト）の書き方を工夫・最適化する技術です。", "特定のタスクのためにモデルの重みを更新するのはファインチューニングです。", "データをベクトルに変換するのはエンベディングです。", "プログラムのバグ修正はデバッグです。"],
    110: ["例示なしでタスクを解かせる手法（Zero-shot）です。", "プロンプトの中にいくつか（few）の回答例を含ませることで、LLMにタスクの解き方を示す手法です。", "全パラメータを再学習するのはフル・ファインチューニングです。", "大規模データによる最初の学習は事前学習（Pre-training）です。"],
    111: ["Low-Rank Adaptation。元の重みは固定し、低ランクの小さな行列だけを学習させることで、計算コストを大幅に下げる手法です。", "すべての重みを学習するのは通常のファインチューニングです。", "モデルの精度（ビット数）を下げるのは量子化（Quantization）です。", "不要な接続を削除するのは剪定（プルーニング）です。"],
    112: ["画像とテキストを同じベクトル空間で表現するよう学習し、Zero-shotでの画像分類などを可能にしたモデルです。", "DALL-EはOpenAIの画像生成モデルです。", "Midjourneyは高品質な画像を生成するサービス名です。CLIPは分類等の基盤技術です。"],
    113: ["LLMが、もっともらしい嘘や事実と異なる情報を自信満々に出力してしまう現象です。", "訓練データに過剰に適合するのは過学習（オーバーフィッティング）です。", "データやモデルの偏りはバイアスです。", "運用中に精度が落ちるのはコンセプトドリフトです。"],
    114: ["Neural Machine Translation。ニューラルネットワーク（Seq2SeqやTransformer）を用いた現在の主流な翻訳方式です。", "Rule-Based Machine Translation。文法規則に基づく古典的な方式です。", "Statistical Machine Translation。統計情報を用いる、NMT以前の主流方式です。", "Example-Based Machine Translation。過去の翻訳例を再利用する方式です。"],
    115: ["クラス（人、車など）ごとに塗り分けるが、個体は区別しません。", "クラスが同じであっても、個々の物体（人A、人B）を別々に識別して塗り分けるタスクです。", "物体をバウンディングボックスで囲むタスクです。", "画像に含まれる主要なクラスを分類するタスクです。"],
    116: ["カメラ、LiDAR、ミリ波レーダーなど複数のセンサーからの情報を統合し、より高精度で信頼性の高い認識を行う技術です。", "既存のデータに変換を加えてデータを水増しする手法です。", "複数のモデルの予測を組み合わせる手法です。", "システムを二重化して障害に備える手法です。"],
    117: ["音声認識（ASR）です。", "Text-to-Speech。入力されたテキストデータを人間のような自然な音声に変換・生成する技術です。", "音の波形などを分析する技術です。", "ノイズキャンセリングなどの信号処理技術です。"],
    118: ["LLMが一度に処理（入力・出力）できるトークンの最大数のことです。窓（ウィンドウ）の広さに例えられます。", "モデルの規模を示す重みの数です。", "ハードウェアのメモリを指す言葉ではありません。", "一度の重み更新に使うデータ数はバッチサイズです。"],
    119: ["Vision Transformerにおいて、画像を小さな正方形の領域（パッチ）に分割し、それをテキストのトークンのように系列データとして扱います。", "画像を構成する最小単位（画素）です。", "CNNで特徴抽出に使う小さな行列です。", "フィルタと同じ意味で使われます。"],
    120: ["テキストなどから動画（ビデオ）を生成するAIです（例: OpenAI's Sora）。", "静止画を生成するのは画像生成AI（Midjourneyなど）です。", "3Dモデルを生成するのは3D生成AIです。", "音声や音楽を生成するのは音声生成AIです。"],
    121: ["AIの出力が人間の価値観、倫理、意図に合致するように微調整し、有害な出力を防ぐためのプロセスです（RLHFなど）。", "大規模データから一般的な知識を学ぶのは事前学習です。", "蒸留は大きなモデルから小さなモデルへ知識を移す技術です。", "量子化はモデルのデータ型を小さくして軽量化する技術です。"],
    122: ["大量のラベルなしデータから、言語のルールや一般的な知識を自己教師あり学習などで学ぶ初期段階です。", "事前学習後、特定のタスク（翻訳、対話など）に特化させるのは微調整（ファインチューニング）です。", "既存の学習済みモデルを別の領域に適用するのは転移学習です。", "能動学習（Active Learning）は効率的に人間がラベル付けするための手法です。"],
    123: ["Minimum Viable Product。実用最小限の製品のことです。", "Proof of Concept（概念実証）。新しいアイデアや技術が実現可能か、期待した効果が得られるかを検証する前段階の工程です。", "Beta版は完成に近いテスト版製品です。", "プロトタイプはシステムの動作やデザインを確認するための試作品です。"],
    124: ["IT運用のためのAI活用（AI for IT Operations）です。", "Machine Learning Operations。機械学習モデルの開発・訓練から、本番環境へのデプロイ、監視、運用までを継続的・自動的に回すための仕組みや体制です。", "データ活用全般の最適化・自動化です。", "ソフトウェア開発と運用の統合です。"],
    125: ["時間の経過とともにデータの傾向や前提条件（概念）が変化し、学習時のモデルでは現在のデータを正しく予測できなくなる現象です。", "モデル自体のアルゴリズムが劣化するわけではありません。", "プログラムの欠陥（バグ）とは異なります。", "数値計算の桁あふれです。"],
    126: ["開発にかかるコストです。", "アノテーションなどのデータ準備にかかるコストです。", "サーバー代などの運用にかかるコストです。", "ROI（投資利益率）を計算する際の投資（I）には、開発フェーズだけでなく運用フェーズも含めたトータルコストを見込む必要があります。"],
    127: ["アジャイル開発において、1〜4週間程度の短い期間（スプリント）で開発・リリースを繰り返す単位です。", "フェーズ（工程）やマイルストーン（中間目標）は、より大きなプロジェクト管理の単位やチェックポイントです。", "クオーターは四半期のことです。"],
    128: ["AIなどの基礎的な理解を促す教育です。", "新しいシステムや業務プロセスの導入に伴う、現場の混乱や抵抗を和らげ、変革を定着させるための管理・支援活動です。", "操作方法などを支援する窓口です。", "説明会そのものを指す言葉としては限定的です。"],
    129: ["企業がAIを導入し利用する際の一般的な指針ですが、名称が異なります。", "経済産業省が策定した、企業がAIガバナンスを構築するための具体的な行動目標や実践例を示した報告書です。", "2025年の崖などを警告した、DX推進の資料です。", "国全体の戦略です。"],
    130: ["システムに異常や故障が発生した際、被害を最小限に抑えるよう、安全な状態（機能制限や停止）に移行させる設計思想です。", "データのコピーを取ることです。", "システムを多重化して止まらないようにするのはフォールトトレランス設計です。", "外部からの攻撃を防ぐ対策です。"],
    131: ["組織がデータ資産を価値あるものとして維持し、収集、蓄積、利用、保護などのライフサイクル全体を適切に管理する活動です。", "大量のデータから有用なパターンを見つけ出す技術です。", "様々な生データを一元的に保存するシステムです。", "分析用に整理されたデータを保存するシステムです。"],
    132: ["AIをどのような業務課題の解決に、どのような形式で適用するか（具体的な利用場面）を定義することです。これが不明確だとプロジェクトが迷走します。", "システムが満たすべき技術的な要件を定義する工程です。", "予算やベンダー選定も重要ですが、まずは目的（ユースケース）が最優先です。"],
    133: ["AIプロジェクトの各段階に潜むリスク（技術的、法的、倫理的リスクなど）を洗い出し、その発生可能性や影響度を評価して対策を講じることです。", "スケジュールの管理です。", "モデルの精度やシステムの安定性を管理することです。", "チームメンバーの管理です。"],
    134: ["人機一体は一般的な協力の表現です。", "AIの予測や判断のプロセスに人間が介入（確認・修正）し、品質を維持しつつAIを再学習させるようなシステム設計の概念です。", "完全に自動化してしまうと、誤判断のリスクが高まる場合があります。", "外部の業者に業務を委託することです。"],
    135: ["AIモデルが本番環境で稼働した後に、予測精度が低下していないか、システムが正常に動いているかを継続的に監視することです。", "システムの動作履歴を記録することです。", "AIの判断の根拠やデータの追跡可能性を確保することです。", "監査は定期的なチェックです。"],
    136: ["現行の法体系において、AI自体は責任の主体になりません。", "開発者は技術的な原因に対応しますが、最終的な責任主体ではありません。", "AIシステムを社会に提供し、利益を得る事業者（提供者）が、利用者や社会に対して説明し、問題を解決する最終的な責任を負うのが一般的です。", "利用者は説明を受ける側です。"],
    137: ["人件費や家賃など、売上に関わらず一定にかかる費用です。", "AIによる自動化（チャットボットによる対応等）は、問い合わせ件数によって増減する人件費（変動費）を抑える効果があります。", "製品の製造に直接かかる費用です。", "すべてのコストが下がるわけではありません。"],
    138: ["データ基盤の整備、AIリテラシー、組織文化など、AIを効果的に導入・活用するための土台が整っている状態を指します。", "IT化のことです。", "DXが完了した状態です。", "クラウド技術を活用している状態です。"],
    139: ["インターネット上で不特定多数の人々に業務（アノテーションやデータ収集など）を委託・外注する手法です。", "短期間で集中してプログラムを開発するイベントです。", "社員への教育です。", "正社員等の雇用です。"],
    140: ["経済産業省の「DXレポート」で警告された、既存システムの老朽化（ブラックボックス化）や人材不足により、2025年以降に多額の経済損失が生じるというシナリオです。", "AIによる雇用喪失などの懸念を指す言葉ではありません。", "不況全体を指す言葉です。"],
    141: ["個人からデータ活用に関する同意・委任を受け、適切なルールに基づいてデータを管理し、第三者（企業など）に提供する事業の仕組みです。", "企業間でデータをやり取りする市場です。", "国や自治体が公開し、誰でも自由に使えるデータです。", "Personal Data Storeのことで、個人が自身のデータを管理する仕組みですが、情報銀行の基盤となる技術概念です。"],
    142: ["既存の技術やビジネスモデルを根底から覆し、新しい市場や価値を生み出すことです。（例：AIによる伝統的産業の変革）。", "新しい価値を創造すること全般を指します。", "事業規模を拡大することです。", "企業間の共同事業のことです。"],
    143: ["すべての値を合計してデータの個数で割った値です。", "データを小さい順（または大きい順）に並べたときに、ちょうど真ん中にある値です。極端な外れ値の影響を受けにくい特徴があります。", "データの中で最も頻繁に出現する値です。", "データのばらつきを表す指標です。"],
    144: ["各データが平均値からどれくらい離れているかの2乗の平均で、データの散らばり具合を示します。", "平均からどれくらい離れているかを示す標準化されたスコアです。", "確率的に得られる値の平均的な見込みです。", "最も大きい値です。"],
    145: ["2つの変数の間にどちらかが増えればもう一方も増える（正）、減る（負）といった関連性の強さを-1から1の間で表す指標です。", "回帰モデルの当てはまりの良さを示す指標です。", "回帰式における傾きです。", "データのばらつきを標準単位で表したものです。"],
    146: ["事象Aが起こったという条件のもとで、事象Bが起こる確率を P(B|A) と表します。", "複数の事象が同時に起こる確率 P(A∩B) です。", "他の変数を考慮せず、ある変数が特定の値をとる確率です。", "ある証拠に基づいて更新された確率です。"],
    147: ["事前確率（もともとの信念）に、尤度（新しい証拠）を組み合わせて事後確率（更新された信念）を求める統計学の基本定理です。", "直角三角形の辺の長さの関係です。", "多数の標本平均の分布が正規分布に近づく定理です。", "試行回数を増やすと標本平均が真の平均に近づく法則です。"],
    148: ["合成関数 f(g(x)) の微分において、外側の関数の微分と内側の関数の微分を掛け合わせるルールのことです（連鎖律）。", "2つの関数の積の微分ルールです。", "分数関数の微分ルールです。", "積の積分に使われる公式です。"],
    149: ["元の行列とかけ合わせると単位行列になる行列です。", "行列の行と列の要素をそっくり入れ替えた行列のことです。 $A^T$ のように表記します。", "対角成分以外がすべて0の正方行列です。", "行数と列数が等しい行列です。"],
    150: ["関数の値が最も急激に減少する方向（勾配ベクトルの逆向き）にパラメータ（重み）を更新し、関数の最小値を探り当てる最適化アルゴリズムです。", "方程式の近似解を求める反復法です。", "誤差の2乗和を最小にするパラメータを求める手法です。", "制約条件付き最適化問題の解法です。"]
};

async function bulkEnrich() {
    console.log('[Bulk Enrich] Updating optionExplanations for Batch 5 (IDs 101-150)...');
    try {
        let updatedCount = 0;
        for (const [id, exps] of Object.entries(enrichment)) {
            const res = await pool.query(
                `UPDATE g_kentei_questions SET optionExplanations = $1 WHERE id = $2`,
                [JSON.stringify(exps), id]
            );
            if (res.rowCount > 0) {
                updatedCount++;
            }
        }
        console.log(`[Bulk Enrich] Successfully updated ${updatedCount} questions.`);
    } catch (err) {
        console.error('[Bulk Enrich] Error:', err.message);
    } finally {
        await pool.end();
    }
}

bulkEnrich();
