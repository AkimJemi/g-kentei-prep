import pkg from 'pg';
const { Pool } = pkg;

const connectionString = 'postgresql://g_kentei_prep_app_db_user:0vZFHekJvsuMexPcBCKx5Ix4Noy7WZJO@dpg-d63nv6cr85hc73bckig0-a.oregon-postgres.render.com/g_kentei_prep_app_db';
const pool = new Pool({
  connectionString,
  ssl: { rejectUnauthorized: false }
});

const enrichment = {
    53: ["2つのカテゴリに分けるタスクの呼称です。", "3つ以上のカテゴリに分けるタスクです。", "1つの数値指標を予測する回帰です。", "多数の変数を扱う統計手法の総称です。"],
    54: ["ブートストラップ抽出した複数のデータで並列学習し、平均をとる手法です。", "逐次的に（直列に）重みを更新しながら精度を上げる手法です。", "モデルの予測値をさらに別のモデルで統合する手法です。", "正規化は過学習防止の手法です。"],
    55: ["多数のモデルを並列に学習させます。", "誤分類されたデータの重要度を上げ、逐次的に学習を進める手法です。", "正規化はデータの前処理です。", "プーリングはCNNで情報を集約する処理です。"],
    56: ["重みの結合で表現するモデルです。", "条件分岐を繰り返して分類や予測を行うモデルです。人が理解しやすい特徴があります。", "確率で分類し、シグモイド関数を使うモデルです。", "確率の独立性を仮定したベイズモデルです。"],
    57: ["ベイズの定理に基づき、各特徴が独立であると仮定したシンプルな分類器です。", "線形判別分析のことです。", "強化学習の行動価値学習アルゴリズムです。", "強化学習のアルゴリズム（行動後に状態を更新）です。"],
    58: ["連続値を予測するタスクです。", "画像から物体を検出しラベル付けするタスクです。", "ラベルなしデータから類似性を基にグループを作る手法です。", "学習済みモデルを流用する手法です。"],
    59: ["ある状態で行動した際の将来の報酬の期待値を表す行動価値関数です。", "遷移確率Pや方策などに関連する用語ですが、この文脈の核心ではありません。", "モデルの誤差を表し、最小化の対象となる関数です。", "0から1の範囲に変換する活性化関数の一種です。"],
    60: ["モデル構築プロセス（前処理、モデル選択、チューニング等）を自動化する技術です。", "ニューラルネットを用いた学習技術そのものの呼称です。", "ネット経由で計算資源を利用する形態です。", "データから知見を抽出するプロセス全体のことです。"],
    61: ["最小化すべき誤差を算出する関数です。", "入力を非線形に変換し、ニューロンの発火をシミュレートする関数です。", "モデルをランク付けするための関数です。", "最小化すべき対象を表す、より広い概念の呼称です。"],
    62: ["発火を制御する関数です。", "予測値と正解の「ズレ」を定義し、最小化の目標となる関数です。", "入力をそのまま出力する関数です。", "空間の基底を張るために使われる関数です。"],
    63: ["重みの更新量や方向を計算するアルゴリズムです。", "そのような専門用語はありません。", "データを一定の範囲に揃える装置のことではありません。", "重みをランダム等で最初に設定する仕組みです。"],
    64: ["入力から出力へ情報を流す過程です。", "出力から入力へ勾配を伝え、重みを効率的に更新するアルゴリズムです。", "ランダムに状態を遷移させる手法です。", "ランダムにシミュレーションを行う手法です。"],
    65: ["勾配が非常に大きくなり学習が不安定になることです。", "層が深くなると勾配が小さくなり、入力層近くの学習が進まなくなる現象です。", "訓練データに合いすぎる現象です。", "次元が増えて学習が困難になる現象です。"],
    66: ["0から1に変換しますが、勾配消失を起こしやすいです。", "双曲線正接関数で、-1から1に変換します。", "負を0、正をそのまま出力し、勾配消失を防ぐ主流の関数です。", "出力を確率（合計1）に変換する関数です。"],
    67: ["データすべてを一度に処理する方法です。", "効率よく勾配を計算するために分けた、データの小グループのことです。", "データを1つずつ処理する方法です。", "ランダムに選ぶこと自体を指す言葉ではありません。"],
    68: ["一度の重み更新プロセスを指します。", "全バッチを一周して更新した回数です。", "訓練データセット全体を1回学習し終える単位です。", "更新プロセスの最小単位を指すことが多いです。"],
    69: ["勾配消失（Vanishing Gradient）により、下層への重み更新が止まる問題です。", "解が見つかるが、それが最適ではない場所のことです。", "一方向には極小だが別からは極大である停滞点です。", "学習が進まない平坦な領域です。"],
    70: ["過学習を防ぐために接続をランダムに切る手法です。", "中間層の出力を正規化し、学習を安定・高速化させる手法です。", "精度が上がらなくなった時点で学習を止める手法です。", "画像を反転・回転させてデータを増やす手法です。"],
    71: ["重みがすべて同じになると対称性が崩れず学習できません。", "0と同様、対称性が崩れないため不適切です。", "He初期化やXavier初期化など、分布を持つ乱数で設定します。", "以前の学習結果がない場合は引き継げません。"],
    72: ["ランダムに一部のニューロンを除外して学習し、汎化性能を高める手法です。", "データのサイズを小さくする処理です。", "画像にフィルタをかける処理です。", "数値を予測するタスクです。"],
    73: ["モデルが学習して自動調整する値です。", "モデル内部で保持される値の総称です。", "中間層（隠れ層）の重みのことです。"],
    74: ["周囲よりは低い（極小）が、全領域で最小ではない地点のことです。", "関数の定義域全体で最小となる地点です。", "勾配が0だが、谷底ではない停滞点です。", "勾配が非常に小さい平坦な領域です。"],
    75: ["関数の極大点付近を指す表現です。", "ある方向からは極小、別の方向からは極大となる勾配0の地点です。", "関数の極小点です。", "数学的性質が異なる点です。"],
    76: ["学習が進むにつれ、更新量（学習率）を小さくして収束させる仕組みです。", "重みを更新する本体のアルゴリズムです。", "データの正規化を行うための仕組みではありません。"],
    77: ["目的関数の勾配を下る方向に重みを更新していく基本的アルゴリズムです。", "制約条件下の最適化手法です。", "ソートや探索のアルゴリズムです。", "グラフを深くたどる探索手法です。"],
    78: ["モデルの最終性能を測るための、学習に一切関与させないデータです。", "ハイパーパラメータの調整やモデル選択、過学習チェックに使うデータです。", "実際の運用環境のデータです。", "一般に公開されているデータセットのことです。"],
    79: ["入力データをミニバッチごとに正規化し、学習を効率化する代表的手法です。", "層ごとに正規化を行う手法（RNN等で利用）です。", "1つのサンプル×チャンネル内で正規化する手法です。"],
    80: ["層を重ねる前の初期の単純なモデルです。", "結合主義（ニューラルネット）の支持者を指す言葉です。", "制御工学から派生した初期の研究分野名です。"],
    81: ["画像を小さく圧縮するプロセスです。", "最終的に1つの出力（クラス等）に繋げる層です。", "画像から空間的な特徴（エッジ等）を抽出するCNNの核となる層です。"],
    82: ["データの微小なズレを許容し、重要な情報を残しながら縮小する層です。", "特徴を抽出する層です。", "時系列を扱う構造を持つ層です。"],
    83: ["静止画に強い、空間的な構造を捉えるモデルです。", "再帰構造を持ち、時系列データや文脈を扱えるモデルです。", "画像を生成する敵対的なモデルです。", "画像を生成する確率的なモデルです。"],
    84: ["勾配消失を長期記憶（セルの保持）で解決したRNNの一種です。", "LSTMを簡略化したモデルです。", "注意機構に基づくモデルで、系列処理の一種ですが構造が異なります。", "CNNにおけるスキップ接続のモデルです。"],
    85: ["VGGはシンプルな重ね合わせモデルです。", "GoogLeNetはインセプションモジュールを用いた複雑なモデルです。", "勾配を直接下層に伝えるスキップ接続を導入し、100層以上の深層化を可能にしたモデルです。", "2012年のブレイクスルーとなったモデルです。"],
    86: ["画像を処理する主要な操作です。", "データを縮小する操作です。", "Transformerの核であり、文脈の中でどの要素が重要かを計算する重み付け機構です。", "RNNで情報を循環させる構造です。"],
    87: ["確率的に生成を行うモデルです。", "生成側と判別側を競わせ、本物に近い画像を生成する有名なモデルです。"],
    88: ["入力を一度圧縮（エンコード）し、再度復元（デコード）することで重要な特徴を抽出するモデルです。", "RNN/CNNは特定の構造を持つネットワークです。", "パーセプトロンは初期の単純なネットです。"],
    89: ["画像全体のクラスを1つだけ出すタスクです。", "画像内の特定の物体を囲むタスクです。", "すべてのピクセルに対して何であるかをラベル付けし、境界を正確に特定するタスクです。", "顔を特定・照合するタスクです。"],
    90: ["全ピクセルを分類するタスクです。", "画像内の物体をバウンディングボックスで囲み、クラスを特定するタスクです。"],
    91: ["CNNはフィルタ内の重みを学習によって最適化していきます。", "ラベルはモデル全体が予測する目標です。"],
    92: ["可変長の入力を処理し、可変長の出力を出す構造です。Transformerなどの基礎概念です。", "RNNはその中の一つの実装技術です。", "MLPは多層パーセプトロンです。", "DQNは強化学習手法です。"],
    93: ["大規模データで学習済みのモデルを、自前の少量のデータで追加学習させて流用する手法です。", "試行錯誤で学ぶ手法です。"]
};

async function bulkEnrich() {
    console.log('[Bulk Enrich] Updating optionExplanations for second batch (IDs 53-100)...');
    try {
        let updatedCount = 0;
        for (const [id, exps] of Object.entries(enrichment)) {
            const res = await pool.query(
                `UPDATE g_kentei_questions SET optionExplanations = $1 WHERE id = $2`,
                [JSON.stringify(exps), id]
            );
            if (res.rowCount > 0) {
                updatedCount++;
            }
        }
        console.log(`[Bulk Enrich] Successfully updated ${updatedCount} questions in this batch.`);
    } catch (err) {
        console.error('[Bulk Enrich] Error:', err.message);
    } finally {
        await pool.end();
    }
}

bulkEnrich();
