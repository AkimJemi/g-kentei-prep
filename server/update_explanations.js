import { readFileSync, writeFileSync } from 'fs';
import { fileURLToPath } from 'url';
import { dirname, join } from 'path';

console.log('Script started');

const __dirname = dirname(fileURLToPath(import.meta.url));
const jsonPath = join(__dirname, '../questions_export.json');

const explanations = {
    1001: [ // 1956 Conference
        "ジョン・マッカーシーらによって開催されました。", // Dartmouth
        "エニアック(ENIAC)は1946年に完成した世界初の汎用電子計算機です。", // ENIAC
        "アラン・チューリングは1950年にチューリング・テストを提案しましたが、この会議には直接関与していません。", // Turing
        "スタンフォード大学は後のAI研究の拠点となりますが、この会議の場所ではありません。" // Stanford
    ],
    1002: [ // John Searle
        "人間のような精神的な状態（理解や意識）を持つAIを指します。", // Strong AI
        "特定のタスクをこなすだけのAIで、意識は持ちません。", // Weak AI
        "汎用AI(AGI)は人間と同等の能力を持つこと指しますが、サールの分類では「強い/弱い」が対になります。", // General AI
        "特化型AIは特定の領域（チェスなど）に限定されたAIです。" // Narrow AI
    ],
    1003: [ // Specific tasks
        "汎用AIは、人間のようにあらゆる課題をこなせるAIです。", // General AI
        "現在のAIのほとんど（画像認識、翻訳など）はこれに分類されます。", // Narrow AI
        "強いAIは意識や心を持つとされるAIの概念です。", // Strong AI
        "自律型AIは、人間の介入なしに行動するAIを指しますが、タスクの範囲（特化か汎用か）とは別の分類です。" // Autonomous AI
    ],
    1004: [ // Symbol meaning
        "フレーム問題は、関係のない事柄を無視することの難しさに関する問題です。", // Frame Problem
        "記号（シンボル）とその対象（意味）が結びついていない（グラウンディングしていない）状態を指します。", // Symbol Grounding
        "停止問題は、プログラムが有限時間で停止するかどうかを判定できないという計算理論の問題です。", // Halting Problem
        "トロッコ問題は、倫理学上の思考実験です。" // Trolley Problem
    ],
    1005: [ // Infinite possibilities
        "次元の呪いは、データの次元が増えると空間が疎になり、学習が難しくなる現象です。", // Curse of Dimensionality
        "世界中で起こりうる全ての事象を考慮しようとすると、計算量が爆発し、行動できなくなる問題です。", // Frame Problem
        "シンボル崩壊という用語は一般的ではありません。", // Symbol Collapse
        "組み合わせの爆発は計算量の急増を指す言葉ですが、ロボットの行動決定における文脈では「フレーム問題」が最も適切です。" // Combinatorial Explosion
    ],
    1006: [ // Moravec's Paradox
        "ハンス・モラベックらが指摘しました。子供でもできるような感知・運動能力の方が、高度な推論よりも計算資源を必要とするという逆説です。", 
        "チューリング・テストは、機械が人間と区別がつかないほど知的かを判定するテストです。", 
        "中国の部屋は、意味を理解せずとも記号操作で対話が可能かという思考実験です。", 
        "フェルミのパラドックスは、地球外文明の存在に関する矛盾を指します。"
    ],
    1007: [ // Imitation Game (Turing)
        "ジョン・マッカーシーはLISPの開発者であり、AIの名付け親です。", 
        "アラン・チューリングが1950年の論文で提案しました。", 
        "マービン・ミンスキーはAIの父の一人ですが、模倣ゲームの提案者ではありません。", 
        "ハーバート・サイモンは論理学者・認知心理学者で、ノーベル経済学賞を受賞しています。"
    ],
    1008: [ // Chinese Room
        "エニアックは初期のコンピュータの名前です。", 
        "チューリングの部屋という用語はありません（チューリング・テストと混同しないように）。", 
        "ジョン・サールが1980年に発表した、強いAI（コンピュータが心を持てるか）への反論です。", 
        "マッカーシーの部屋という用語はありません。"
    ],
    1009: [ // Herbert Simon
        "ハーバート・サイモンは、アレン・ニューウェルと共にLogic Theoristを開発しました。", 
        "レイ・カーツワイルはシンギュラリティの提唱者として知られています。", 
        "アンドリュー・ンは現代のディープラーニング研究者（Google Brain創設など）です。", 
        "ヨシュア・ベンジオは現代のディープラーニング研究者（GANや注意機構など）です。"
    ],
    1010: [ // Toy Problem
        "現実世界の複雑な問題ではなく、ルールが明確で限定的な問題（迷路、パズル）しか解けなかったことを指します。", 
        "ショート・プロブレムという用語は一般的ではありません。", 
        "シンプル・ケースは一般的な用語ですが、AI史の文脈ではトイ・プロブレムが使われます。", 
        "ダミー・パズルという用語はありません。"
    ],
    1011: [ // 1950 Turing Paper
        "1946年はENIACが公開された年です。",
        "\"Computing Machinery and Intelligence\"（計算する機械と知能）がMind誌に掲載されました。",
        "1956年はダートマス会議の年です。",
        "1960年代は既に第一次AIブームの中です。"
    ],
    1012: [ // John McCarthy definition
        "ダートマス会議の提案書において、AIをこのように定義しました。",
        "ジェフリー・ヒントンはディープラーニングのゴッドファーザーの一人です。",
        "サム・アルトマンはOpenAIのCEOです。",
        "イーロン・マスクはOpenAIの共同設立者の一人ですが、この定義の考案者ではありません。"
    ],
    1013: [ // Physical Symbol System Hypothesis
        "身体性仮説は、知能には身体が不可欠であるとする、記号主義とは対極の考え方です。",
        "物理的な記号システムが一般的知能動作に必要な十分条件を持つという仮説です。",
        "コネクショニズムは、脳の神経回路網を模倣するアプローチ（ニューラルネットワーク）です。",
        "量子脳理論は、脳の働きを量子力学で説明しようとする仮説です。"
    ],
    1014: [ // Logic Theorist
        "ラッセルとホワイトヘッドの『プリンキピア・マテマティカ』の定理を証明しました。",
        "General Problem Solver (GPS) はLogic Theoristの後継として開発された汎用問題解決プログラムです。",
        "ELIZAは1966年に開発された対話システムです。",
        "MYCINは1970年代のエキスパートシステム（血液疾患診断）です。"
    ],
    1015: [ // Weak AI behaviorism
        "機能主義は、心の働きは機能（入力と出力の関係）によって決まるとする立場です。",
        "行動主義的な観点では、知的な行動を示せば、内部に意識があるかどうかは問わないとされます（弱いAIの立場）。",
        "消去主義は、心や意識といった概念そのものを否定する立場です。",
        "独我論は、自分だけが存在し、他者は存在しない（あるいは証明できない）とする哲学的な立場です。"
    ],
    1016: [ // Embodiment
        "ロドニー・ブルックスらが提唱した、知能は環境との相互作用（身体）から生まれるという考え方です。",
        "脱身体性は逆の意味になります。",
        "二元論は、心と体を別のものとして考えるデカルト的な哲学です。",
        "唯物論は、すべての存在は物質であるとする考え方です。"
    ],
    1017: [ // Rational Agent
        "人間の模倣は、必ずしも合理的（目標達成に最適）とは限りません（人間はミスをするため）。",
        "思考プロセスそのものの正確性よりも、結果（行動）の合理性が重視されます。",
        "ラッセルとノーヴィグの教科書などで定義される、成果（期待効用や報酬）を最大化するエージェントです。",
        "計算速度は性能の一部ですが、合理性の定義そのものではありません。"
    ],
    1018: [ // ELIZA
        "ALICEはELIZAに触発されて作られた後のチャットボットです。",
        "SIRIはAppleの音声アシスタントです。",
        "単純なパターンマッチングで、相手の言葉をオウム返しすることで対話を成立させました。",
        "SHRDLUは積み木の世界を扱うプログラムです。"
    ],
    1019: [ // SHRDLU
        "「青い積み木を赤い積み木の上に乗せて」といった自然言語の命令を理解し、実行しました。",
        "Deep Blueはチェス専用のAIです。",
        "AlphaGoは囲碁のAIです。",
        "Watsonはクイズ回答や質問応答システムです。"
    ],
    1020: [ // Connectionism
        "ニューロンの結合強度（重み）の変化によって学習するという、現在のディープラーニングの源流です。",
        "フォルマリズムは形式主義のことです。",
        "構造主義は哲学や言語学の用語です。",
        "記号主義（シンボリズム）は、コネクショニズムと対立する、記号操作に基づくAIのアプローチです。"
    ],
    2001: [ // Expert System
        "ディープラーニングは第3次AIブーム（2010年代〜）の中心技術です。",
        "人間の専門家の知識をルールとして記述し、推論を行うシステムです。MYCINなどが有名です。",
        "ビッグデータは第3次AIブームを支える要素の一つですが、技術そのものの名前ではありません。",
        "強化学習は学習手法の一つで、ブーム全体を指す言葉ではありません。"
    ],
    2002: [ // ILSVRC 2012
        "Kaggleはデータ分析コンペティションのプラットフォームです。",
        "ImageNet Large Scale Visual Recognition Challenge。トロント大学のチーム（SuperVision）が圧倒的な精度で優勝しました。",
        "RoboCupはロボット工学の競技会です。",
        "DARPAはアメリカ国防高等研究計画局で、コンペの主催者になることはありますが、コンペ自体の名前ではありません。"
    ],
    2003: [ // Singularity
        "ビッグバンは宇宙の始まりです。",
        "技術的特異点とも呼ばれます。AIが自らより賢いAIを作り出せるようになる時点を指します。",
        "DXはITによる業務変革です。",
        "メタバースは仮想空間のことです。"
    ],
    2004: [ // Watson
        "Deep Blueは1997年にチェス王者に勝利したIBMのマシンです。",
        "Wikipediaなどの膨大なテキストデータを検索し、自然言語の質問に答えました。",
        "Blue GeneはIBMのスーパーコンピュータプロジェクトです。",
        "HALは映画『2001年宇宙の旅』に登場する架空のAIです。"
    ],
    2005: [ // Savant-like AI
        "「バカなAI」という表現は一般的ではありません。",
        "特定の計算や記憶には驚異的な能力を発揮するが、単純な社会的常識などが欠けている状態を指します。",
        "攻殻機動隊はサイバーパンク作品です。",
        "ブラックボックスは、AIの判断根拠が見えない可読性の低さを指す言葉です（欠点ではありますが、意味が異なります）。"
    ],
    2006: [ // Japan AI Strategy
        "10万人では不足とされました。",
        "AIのエキスパートだけでなく、AIを応用できる人材（25万人）を含めた目標です。",
        "50万人は少し多すぎます。",
        "100万人は全学生を対象としたリテラシー教育レベルの数字に近いかもしれません。"
    ],
    2007: [ // Big Data
        "オープンデータは、誰でも自由に使えるデータのことです。",
        "Volume（量）、Variety（多様性）、Velocity（速度）の「3つのV」などで定義されます。",
        "IoTはモノのインターネットで、ビッグデータの発生源の一つです。",
        "ブロックチェーンは分散型台帳技術です。"
    ],
    2008: [ // AI Winter
        "秋とは言いません。",
        "第1次ブーム後（1970年代）と第2次ブーム後（1990年代）に発生しました。",
        "氷河期という表現も使われることがありますが、一般的には「AIの冬」が定着しています。",
        "停滞期も意味は通じますが、専門用語としては「冬」です。"
    ],
    2009: [ // AlphaGo Match
        "東京ではありません。",
        "北京での対局も（AlphaGo Masterなど）ありましたが、イ・セドル戦はソウルです。",
        "Google DeepMind Challenge Matchとして韓国のソウルで開催されました。",
        "サンフランシスコではありません。"
    ],
    2010: [ // Attention is All You Need
        "Googleの研究者らによって発表され、その後のBERTやGPTなどの基盤となりました。",
        "ResNetは2015年の画像認識の論文です。",
        "Deep Residual LearningはResNetの論文タイトルの一部ですが、2015年です。",
        "ImageNet Classificationは2012年のAlexNetの論文に関連します。"
    ],
    2011: [ // ChatGPT
        "GPT-2は2019年に発表され、危険すぎるとして当初は完全公開されなかったモデルです。",
        "GPT-3は2020年に発表された1750億パラメータのモデルです。",
        "GPT-3.5をベースにした対話モデルとして公開され、史上最速で1億ユーザーを獲得しました。",
        "GPT-4は2023年に公開されたマルチモーダルモデルです。"
    ],
    2012: [ // Non-profit organization
        "Google BrainはGoogleの社内プロジェクトです。",
        "DeepMindは英国の企業で、2014年にGoogleに買収されました。",
        "イーロン・マスクやサム・アルトマンらによって、汎用人工知能を人類に益する形で作ることを目的に設立されました。",
        "Meta AIはMeta（旧Facebook）のAI研究部門です。"
    ],
    2013: [ // Edge AI
        "クラウドAIはサーバー側で処理を行う形態です。",
        "スマートフォンやIoTデバイスなど、ユーザー側の端末で処理を行う技術です。通信遅延がなく、プライバシー保護に優れます。",
        "ハイブリッドAIはクラウドとエッジを組み合わせる考え方ですが、端末上で動かすこと自体を指す言葉としてはエッジAIが適切です。",
        "ローカルLLMはエッジAIの一形態（LLMを動かす場合）ですが、質問はより広い概念（端末上でのAI駆動）を指しています。"
    ],
    2014: [ // 5th Gen Computer
        "通産省（現経産省）が主導し、1982年から10年間で570億円が投じられましたが、商業的な成功には至りませんでした。",
        "AI-Japanというプロジェクト名はありません。",
        "スーパーコンピュータ「京」は2010年代のプロジェクトです。",
        "ムーンショット計画は2020年代の内閣府の大型研究開発プログラムです。"
    ],
    2015: [ // Law of Accelerating Returns
        "テクノロジーの進化は直線的ではなく指数関数的に加速するという説で、シンギュラリティ到来の根拠とされています。",
        "ビル・ジョイはSun Microsystemsの共同創業者で、AIの危険性を警告した人物です。",
        "ニック・ボストロムは『スーパーインテリジェンス』の著者で、実存的リスクを論じました。",
        "ユヴァル・ノア・ハラリは歴史学者で『サピエンス全史』の著者です。"
    ],
    2016: [ // Deep Learning Breakthrough
        "機械学習（マシンラーニング）はより広い概念で、1980年代から普及しています。",
        "統計的学習は機械学習の理論的基盤の一つです。",
        "多層ニューラルネットワーク（ディープニューラルネットワーク）を用いた学習手法で、認識精度が飛躍的に向上しました。",
        "データマイニングは大量のデータから知識を取り出す技術の総称です。"
    ],
    2017: [ // Recursive Self-Improvement
        "I.J.グッドが提唱した概念で、AIが自身のソースコードを改良し続けることで、知能が無限に増大するとされます。",
        "自己複製は単にコピーを作ることで、必ずしも知能の向上を意味しません。",
        "オートメーションは自動化のことです。",
        "特異点（シンギュラリティ）はこの現象によって到達する時点のことです。"
    ],
    2018: [ // EU AI Act
        "GDPR（一般データ保護規則）は個人情報保護に関する規則で、2018年に施行されました。",
        "世界初の包括的なAI規制法案で、リスクベースのアプローチ（AIのリスクレベルに応じた規制）を採用しています。",
        "DMA（デジタル市場法）は巨大IT企業の市場独占を防ぐ法律です。",
        "DSA（デジタルサービス法）は違法コンテンツ対策などの法律です。"
    ],
    2019: [ // Multimodal
        "ユニバーサルAIという用語は一般的ではありません（汎用AIとは異なります）。",
        "複数のモード（視覚、聴覚、言語など）を組み合わせて情報を処理・生成する技術です。",
        "シングルモーダルは単一のデータ形式（テキストのみ、画像のみ）を扱うことです。",
        "クロスプラットフォームは異なるOSでソフトが動くことを指す用語です。"
    ],
    2020: [ // Open Source
        "クローズドソースはソースコードを公開しない形態です。",
        "プロプライエタリは独占的・私有的なソフトウェアのことです。",
        "モデルの重みやコードが一般に公開され、商用・非商用を問わず利用・改変が可能（ライセンスによる）な形態です。",
        "フリーウェアは無料で使えるソフトですが、必ずしもソースコードが公開されているとは限りません。"
    ],
    3001: [ // Classification
        "データがどのクラス（カテゴリ）に属するかを予測する問題です（例：スパムかそうでないか）。",
        "回帰は数値を予測する問題です。",
        "クラスタリングは正解ラベルを使わずにデータをグループ分けする教師なし学習です。",
        "次元削減はデータの特徴量を減らす処理です。"
    ],
    3002: [ // Regression
        "分類はカテゴリを予測する問題です。",
        "連続する数値を予測する問題です（例：明日の気温、株価、売上予測）。",
        "クラスタリングはデータのグループ化です。",
        "次元削減はデータの圧縮や可視化に使われます。"
    ],
    3003: [ // Overfitting
        "学習不足（未学習）は、モデルが単純すぎて訓練データすら捉えられていない状態です。",
        "訓練データの細かいノイズまで学習してしまい、新しいデータに対する予測性能（汎化性能）が下がる現象です。",
        "汎化不全は過学習の結果として起こる状態ですが、現象自体の名前としては過学習が適切です。",
        "バイアス（偏り）が高い状態は、むしろ学習不足に近い（モデルがデータに適合できていない）状態を指すことが多いです。"
    ],
    3004: [ // Cross Validation
        "ホールドアウト法はデータを「訓練用」と「テスト用」の2つ（あるいは検証用を含めて3つ）に分割するだけの方法です。",
        "データをK個に分割し、そのうち1つをテスト用、残りを訓練用として、K回繰り返して平均をとる手法です。",
        "ブートストラップは重複を許してランダムにデータをサンプリングする手法です。",
        "ランダムサンプリングは母集団から無作為に標本を抽出することです。"
    ],
    3005: [ // Random Forest
        "多数の決定木を作り、その結果を統合（アンサンブル）して予測精度を高めるバギングの代表的なアルゴリズムです。",
        "ロジスティック回帰は線形モデルによる確率予測（分類）です。",
        "k近傍法は距離に基づく分類手法です。",
        "SVM（サポートベクターマシン）は決定境界のマージンを最大化する手法です。"
    ],
    3006: [ // k-NN
        "k-means（k平均法）はクラスタリング（教師なし学習）の手決です。",
        "未知のデータの近くにあるk個の既知データの多数決でラベルを決める、シンプルな教師あり学習手法です。",
        "k次元木は空間探索のためのデータ構造です。",
        "k主成分は主成分分析で選ぶ成分数のことなどを指す文脈がありますが、手法名ではありません。"
    ],
    3007: [ // Regularization
        "モデルの複雑さにペナルティを課すことで、過学習（重みの肥大化）を防ぐテクニックです。",
        "非線形化は活性化関数などでモデルに表現力を持たせることです。",
        "正規化（Normalization）はデータを一定の範囲（0〜1など）に収める前処理です（※混同しやすいので注意）。",
        "標準化はデータを平均0、分散1に変換する前処理です。"
    ],
    3008: [ // Reinforcement Learning
        "環境の中で試行錯誤しながら、得られる報酬の合計が最大になるような行動方針（方策）を学習します。",
        "教師あり学習は、入力と正解（ラベル）のペアから学習します。",
        "教師なし学習は、正解ラベルのないデータから構造やパターンを見つけ出します。",
        "自己学習は、自分自身でラベルを生成して学習する（自己教師あり学習）などを指す場合がありますが、質問の定義は強化学習です。"
    ],
    3009: [ // SVM
        "クラスを分ける境界線（超平面）と、最も近いデータ点（サポートベクター）との距離（マージン）を最大化するように学習します。",
        "PCA（主成分分析）は次元削減の手法です。",
        "LDA（線形判別分析）はクラス間の分散を最大化、クラス内の分散を最小化するように射影する手法です。",
        "決定木は条件分岐によってデータを分割していく手法です。"
    ],
    3010: [ // PCA
        "クラスタリングはデータをグループ化する手法です。",
        "データの分散が最大になる方向（主成分）を見つけ、情報の損失を最小限に抑えつつ次元を減らす手法です。",
        "回帰は数値を予測する手法です。",
        "ブースティングはアンサンブル学習の一種です。"
    ],
    3011: [ // Recall
        "精度（Accuracy）は全体の中で正解した割合です（正/正＋負/負）。",
        "実際には正（Positive）であるデータのうち、どれだけを正しく検知できたかの割合です。「取りこぼし」を減らしたい病気の発見などで重要です。",
        "適合率（Precision）は「正」と予測した中にどれだけ本物の「正」が含まれていたかです。",
        "F値は再現率と適合率の調和平均です。"
    ],
    3012: [ // Precision
        "精度（Accuracy）は全体の正答率です。",
        "再現率（Recall）は「見逃し」の少なさを評価する指標です。",
        "予測が正（Positive）だったもののうち、実際に正しかった割合です。「誤検知（冤罪）」を減らしたいスパムメール判定などで重要です。",
        "特異度（Specificity）は実際には負（Negative）であるものを正しく負と予測できた割合です。"
    ],
    3013: [ // Binary Classification
        "データを2つのクラス（正例と負例、0と1など）に分けるタスクです。",
        "多クラス分類は3つ以上のクラスに分けるタスクです。",
        "単回帰は1つの説明変数から目的変数を予測する回帰分析です。",
        "多変量解析は複数の変数を扱う統計的・数学的手法の総称です。"
    ],
    3014: [ // Bagging
        "ブートストラップサンプリングによって生成した複数のデータセットでモデル（弱学習器）を並列に学習させ、単純平均や多数決で統合します。ランダムフォレストが代表例です。",
        "ブースティングはモデルを「直列」に繋ぎ、前のモデルの弱点を次のモデルが補うように学習します。",
        "スタッキングは異なる種類のモデルの予測結果を入力として、さらに別のモデル（メタモデル）で学習させる手法です。",
        "正則化は過学習を防ぐための工夫です。"
    ],
    3015: [ // Boosting
        "バギングは独立したモデルを並列に学習させます（重みの調整による連鎖はありません）。",
        "前のモデルが誤分類したデータの重要度（重み）を上げ、次のモデルがそのデータを重点的に学習するようにする手法です。AdaBoostや勾配ブースティング決定木(GBDT)が有名です。",
        "正規化はデータの前処理です。",
        "プーリングはCNNなどで画像を縮小する処理です。"
    ],
    3016: [ // Decision Tree
        "ニューラルネットワークはニューロンの結合によるモデルです。",
        "質問項目（属性）に対するYes/Noなどの分岐を繰り返して分類や予測を行うモデルです。人間が過程を理解しやすい（ホワイトボックス性が高い）です。",
        "ロジスティック回帰は確率を計算する線形モデルです。",
        "ナイーブベイズは確率論（ベイズの定理）に基づくモデルです。"
    ],
    3017: [ // Naive Bayes
        "特徴量同士が互いに独立であるという「単純（Naive）」な仮定を置くことで計算を簡単にしたベイズ分類器です。テキスト分類（スパム判定）などで強力です。",
        "LDA（潜在的ディリクレ配分法）はトピックモデルなどに使われます（※線形判別分析のLDAとは別物）。",
        "Q学習は強化学習の手法です。",
        "SARSAは強化学習の手法です。"
    ],
    3018: [ // Clustering (Unsupervised)
        "回帰は教師あり学習です。",
        "物体検出は教師あり学習（通常）です。",
        "データ間の距離や類似度に基づいて、似たもの同士をグループ（クラスタ）にまとめる教師なし学習です。",
        "転移学習は学習済みモデルの知識を別のタスクに流用する手法です。"
    ],
    3019: [ // Q-function
        "ある状態sで行動aをとったときに、将来にわたって得られる報酬の総和（期待値）を表す行動価値関数です。",
        "P関数という用語は一般的ではありません（方策関数π(a|s)や遷移確率P(s'|s,a)などはあります）。",
        "Loss関数（損失関数）は学習時の誤差を表す関数です。",
        "Sigmoid関数は活性化関数の一種です。"
    ],
    3020: [ // AutoML
        "Automated Machine Learning。データの前処理、特徴量エンジニアリング、モデル選択、ハイパーパラメータ調整などを自動化する技術です。",
        "Deep Learningは技術そのものの名前です。",
        "Cloud Computingは計算資源の提供形態です。",
        "Data Miningはデータから知見を発掘するプロセス全体を指します。"
    ]
};
function updateExplanations() {
    try {
        console.log('Reading questions...');
        const data = readFileSync(jsonPath, 'utf8');
        const questions = JSON.parse(data);
        let updatedCount = 0;

        questions.forEach(q => {
            if (explanations[q.id]) {
                q.optionExplanations = explanations[q.id];
                updatedCount++;
            }
        });

        console.log(`Writing updates for ${updatedCount} questions...`);
        writeFileSync(jsonPath, JSON.stringify(questions, null, 2), 'utf8');
        console.log('Successfully updated questions_export.json');

    } catch (error) {
        console.error('Error updating explanations:', error);
    }
}

updateExplanations();
