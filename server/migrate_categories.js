import pkg from 'pg';
const { Pool } = pkg;

const pool = new Pool({
  connectionString: 'postgresql://g_kentei_prep_app_db_user:0vZFHekJvsuMexPcBCKx5Ix4Noy7WZJO@dpg-d63nv6cr85hc73bckig0-a.oregon-postgres.render.com/g_kentei_prep_app_db',
  ssl: { rejectUnauthorized: false }
});

// ===================================================
// STEP 1: Category renames (old ID → new ID)
// ===================================================
const RENAMES = [
  {
    oldId: '人工知能（AI）とは',
    newId: '人工知能とは',
    title: '人工知能とは',
    icon: 'Brain', color: 'text-blue-400', bg: 'bg-blue-400/10', displayorder: 0
  },
  // 人工知能をめぐる動向: same ID, just update displayorder
  {
    oldId: '人工知能をめぐる動向',
    newId: '人工知能をめぐる動向',
    title: '人工知能をめぐる動向',
    icon: 'Cpu', color: 'text-indigo-400', bg: 'bg-indigo-400/10', displayorder: 1
  },
  {
    oldId: '機械学習の具体的手法',
    newId: '機械学習の概要',
    title: '機械学習の概要',
    icon: 'Database', color: 'text-emerald-400', bg: 'bg-emerald-400/10', displayorder: 2
  },
  // ディープラーニングの概要: same ID, just update displayorder
  {
    oldId: 'ディープラーニングの概要',
    newId: 'ディープラーニングの概要',
    title: 'ディープラーニングの概要',
    icon: 'Zap', color: 'text-amber-400', bg: 'bg-amber-400/10', displayorder: 3
  },
  {
    oldId: 'ディープラーニングの手法',
    newId: 'ディープラーニングの要素技術',
    title: 'ディープラーニングの要素技術',
    icon: 'Layers', color: 'text-rose-400', bg: 'bg-rose-400/10', displayorder: 4
  },
  {
    oldId: 'ディープラーニングの社会実装に向けて',
    newId: 'ディープラーニングの応用例',
    title: 'ディープラーニングの応用例',
    icon: 'Shield', color: 'text-purple-400', bg: 'bg-purple-400/10', displayorder: 5
  },
  {
    oldId: '数理・統計',
    newId: 'AIに必要な数理・統計知識',
    title: 'AIに必要な数理・統計知識',
    icon: 'Terminal', color: 'text-slate-400', bg: 'bg-slate-400/10', displayorder: 7
  },
  {
    oldId: '法律・契約',
    newId: 'AIに関する法律と契約',
    title: 'AIに関する法律と契約',
    icon: 'BookOpen', color: 'text-teal-400', bg: 'bg-teal-400/10', displayorder: 8
  },
  {
    oldId: '倫理・ガバナンス',
    newId: 'AI倫理・AIガバナンス',
    title: 'AI倫理・AIガバナンス',
    icon: 'Award', color: 'text-orange-400', bg: 'bg-orange-400/10', displayorder: 9
  },
];

// ===================================================
// STEP 2: New category
// ===================================================
const NEW_CATEGORY = {
  id: 'AIの社会実装に向けて',
  title: 'AIの社会実装に向けて',
  icon: 'Rocket',
  color: 'text-cyan-400',
  bg: 'bg-cyan-400/10',
  displayorder: 6
};

// ===================================================
// STEP 3: New questions for "AIの社会実装に向けて"
// Sub-topics: AIプロジェクトの進め方 / データの収集・加工・分析・学習
// ===================================================
const NEW_QUESTIONS = [
  // --- AIプロジェクトの進め方 ---
  {
    question: 'AIプロジェクトにおけるPoC（Proof of Concept）の主な目的として最も適切なものはどれか。',
    options: ['本番環境へのフル機能の実装を完成させること', 'AIの技術的な実現可能性やビジネス価値を小規模で検証すること', 'すべてのステークホルダーへの最終成果物を提出すること', 'システムの運用・監視体制を確立すること'],
    correctAnswer: 1,
    explanation: 'PoCはProof of Conceptの略で、AIソリューションが技術的に実現可能か、またビジネス課題を解決できるかを、大規模な投資をする前に小規模なプロトタイプで検証するフェーズです。',
    optionExplanations: [
      'フル機能の実装は本番開発フェーズの目的であり、PoCではありません。',
      '正解。PoCは技術的実現可能性とビジネス価値を低コスト・短期間で確認することが目的です。',
      '最終成果物の提出はプロジェクトの完了フェーズの目的です。',
      '運用・監視体制の確立はMLOpsやリリース後のフェーズで行います。'
    ]
  },
  {
    question: 'AIプロジェクトのライフサイクルとして、一般的に正しい順序はどれか。',
    options: [
      '課題定義 → データ収集 → モデル開発 → 評価・改善 → 本番運用',
      'データ収集 → 課題定義 → モデル開発 → 本番運用 → 評価・改善',
      'モデル開発 → データ収集 → 課題定義 → 評価・改善 → 本番運用',
      '本番運用 → 課題定義 → データ収集 → モデル開発 → 評価・改善'
    ],
    correctAnswer: 0,
    explanation: 'AIプロジェクトは「①ビジネス課題の定義 → ②データ収集・整備 → ③モデル開発・学習 → ④評価・改善 → ⑤本番環境へのデプロイと運用」という順序で進めるのが標準的です。',
    optionExplanations: [
      '正解。課題定義から始まりデータ収集、モデル開発、評価・改善、本番運用の順が標準です。',
      'データ収集より先に課題定義が必要です。何のためのデータかを明確にしてから収集します。',
      'モデル開発は課題定義とデータ収集の後に行います。',
      '本番運用はライフサイクルの最後のフェーズです。'
    ]
  },
  {
    question: 'AIシステム開発における「アジャイル開発」のアプローチの説明として最も適切なものはどれか。',
    options: [
      '最初に完全な要件定義を行い、後工程に変更を一切加えない開発手法',
      '短いサイクル（スプリント）で開発・評価を繰り返し、継続的に改善する手法',
      'AIモデルの学習のみに特化した開発手法',
      '一度だけ大規模なデータ収集を行い、モデルを固定する手法'
    ],
    correctAnswer: 1,
    explanation: 'アジャイル開発は短いイテレーション（スプリント）を繰り返しながら、フィードバックをもとに継続的に改善する手法です。AIプロジェクトのような不確実性が高い領域に適しています。',
    optionExplanations: [
      '最初に完全な要件定義を行い後から変更しないのはウォーターフォール開発の特徴です。',
      '正解。アジャイル開発の核心は短いサイクルでの反復的な開発と継続的改善です。',
      'アジャイル開発はモデル学習だけでなく、プロジェクト全体の進め方に関する手法です。',
      'データ収集やモデルを固定することはアジャイルの考え方と逆行します。'
    ]
  },
  {
    question: 'AIプロジェクトにおいてステークホルダーとして含まれないことが多いのはどれか。',
    options: ['データサイエンティスト', 'ビジネス部門の担当者', 'AIシステムのエンドユーザー', '競合他社の開発者'],
    correctAnswer: 3,
    explanation: 'AIプロジェクトのステークホルダーには、データサイエンティスト・エンジニア、ビジネス担当者、経営層、エンドユーザー、法務・コンプライアンス担当者などが含まれますが、競合他社の開発者は通常含まれません。',
    optionExplanations: [
      'データサイエンティストはAIシステムの主要な開発者として必ずステークホルダーに含まれます。',
      'ビジネス部門はAIの活用要件を定義する重要なステークホルダーです。',
      'エンドユーザーはシステムの使いやすさやニーズを代表する重要なステークホルダーです。',
      '正解。競合他社の開発者は社内プロジェクトのステークホルダーには通常含まれません。'
    ]
  },
  {
    question: 'MLOps（Machine Learning Operations）の説明として最も適切なものはどれか。',
    options: [
      '機械学習モデルの数学的な最適化アルゴリズムのこと',
      '機械学習の開発・デプロイ・監視・再学習のサイクルを効率化・自動化する実践と文化',
      '機械学習データセットのラベリング（アノテーション）作業のこと',
      '機械学習モデルの精度評価指標のこと'
    ],
    correctAnswer: 1,
    explanation: 'MLOpsはMachine LearningとDevOpsを組み合わせた概念で、モデルの開発から本番デプロイ、継続的な監視・再学習・改善までのライフサイクル全体を効率化・自動化するための実践・ツール・文化です。',
    optionExplanations: [
      '最適化アルゴリズムはMLの学習方法に関する話で、MLOpsとは異なります。',
      '正解。MLOpsはモデルの開発から運用・保守・再学習までのサイクルを自動化・効率化することです。',
      'アノテーション作業はデータ準備の工程の一部であり、MLOpsの全体像ではありません。',
      '精度評価指標（Accuracy、F値など）はモデル評価の話であり、MLOpsとは異なります。'
    ]
  },
  {
    question: 'AIプロジェクトのKPI（重要業績評価指標）設定において最も重要な考え方はどれか。',
    options: [
      'AIモデルの技術的精度（Accuracy）のみをKPIとして設定する',
      '達成困難な高い目標を設定し、チームのモチベーションを高める',
      'ビジネス上の目標と連動した、測定可能で意味のある指標を設定する',
      'AIシステムの学習時間を短縮することをKPIとする'
    ],
    correctAnswer: 2,
    explanation: 'AIプロジェクトのKPIはビジネス目標（売上向上、コスト削減、顧客満足度改善など）と連動させ、定量的に測定できることが重要です。技術的な精度だけでなくビジネスインパクトを評価する指標が必要です。',
    optionExplanations: [
      '技術的な精度のみでは、ビジネス価値への貢献度が測れません。ビジネス指標との連動が必要です。',
      '非現実的な目標設定はチームの疲弊につながります。SMARTな目標設定が推奨されます。',
      '正解。ビジネス目標と連動した測定可能なKPIを設定することが最も重要です。',
      '学習時間の短縮は効率化の一側面ですが、ビジネス価値を直接示すKPIとはなりません。'
    ]
  },
  {
    question: 'AIプロジェクトにおける「データドリフト」の説明として正しいものはどれか。',
    options: [
      '学習データのファイルが誤って削除されてしまう現象',
      '本番環境のデータの統計的な性質が、学習時のデータと乖離していく現象',
      'データを複数のサーバーに分散して保存する技術',
      'ニューラルネットワークの勾配が消えてしまう現象'
    ],
    correctAnswer: 1,
    explanation: 'データドリフトとは、モデルを本番運用している間に入力データの分布や統計的性質が変化し、学習時のデータと乖離していく現象です。これによりモデルの精度が低下するため、定期的なモニタリングと再学習が必要です。',
    optionExplanations: [
      'データの削除はデータ管理上の問題であり、データドリフトとは異なります。',
      '正解。データドリフトは本番データの統計的性質が学習データから乖離する現象です。',
      '分散データ保存はデータアーキテクチャの話であり、データドリフトとは無関係です。',
      '勾配消失問題はディープラーニングの学習上の問題であり、データドリフトとは別の概念です。'
    ]
  },
  {
    question: 'AIシステムの本番運用において、「モデルの再学習（Retraining）」が必要になる典型的な理由はどれか。',
    options: [
      'AIモデルのソースコードが変更されたから',
      '本番データの傾向変化（データドリフト）によりモデル精度が低下したから',
      'AIシステムのサーバーをより高性能なものに交換したから',
      'プロジェクトの開発メンバーが変更されたから'
    ],
    correctAnswer: 1,
    explanation: '本番環境で運用するAIモデルは、時間の経過とともにデータの傾向が変化（データドリフト）することで予測精度が低下します。定期的にまたは精度低下を検知した際に新しいデータで再学習することが必要です。',
    optionExplanations: [
      'ソースコードの変更はシステム改修に関する話であり、必ずしも再学習の直接的な理由ではありません。',
      '正解。データドリフトによる精度低下が再学習の最も典型的な理由です。',
      'サーバーの交換はインフラの話であり、直接再学習の理由にはなりません。',
      '開発メンバーの変更はプロジェクト管理上の変更であり、再学習の理由にはなりません。'
    ]
  },
  {
    question: '「AIプロジェクトにおけるフィジビリティスタディ」の目的として最も適切なものはどれか。',
    options: [
      '最終的なAIモデルの学習を完了させること',
      '提案するAIソリューションの技術的・経済的・組織的な実現可能性を事前に評価すること',
      'AIシステムの本番リリース後のパフォーマンス監視を行うこと',
      'AIシステムを利用するエンドユーザーのトレーニングを実施すること'
    ],
    correctAnswer: 1,
    explanation: 'フィジビリティスタディ（実現可能性調査）は、AIプロジェクトを本格的に開始する前に、技術的な実現可能性・コスト対効果・組織的な受け入れ可能性などを事前に評価するための活動です。',
    optionExplanations: [
      '最終的なモデル学習の完了はプロジェクトの開発フェーズの作業です。',
      '正解。フィジビリティスタディはプロジェクト開始前の実現可能性評価です。',
      '本番リリース後の監視はMLOpsや運用フェーズの活動です。',
      'エンドユーザーのトレーニングはリリース後の導入支援活動です。'
    ]
  },
  // --- データの収集・加工・分析・学習 ---
  {
    question: 'アノテーション（Annotation）の説明として正しいものはどれか。',
    options: [
      'モデルのハイパーパラメータを調整する作業',
      '機械学習の学習データに対して正解ラベル（タグ）を付与する作業',
      'AIシステムのAPIを設計・定義する作業',
      '学習済みモデルをサーバーにデプロイする作業'
    ],
    correctAnswer: 1,
    explanation: 'アノテーションとは、画像や文章などの生データに対して「これは猫の画像」「このメールはスパム」などの正解ラベルを人手で付与する作業です。教師あり学習には高品質なアノテーションデータが不可欠です。',
    optionExplanations: [
      'ハイパーパラメータの調整はモデルチューニングの作業であり、アノテーションとは異なります。',
      '正解。アノテーションはデータに正解ラベルを付与する、教師あり学習の根幹となる作業です。',
      'API設計はシステム開発の設計工程であり、アノテーションとは無関係です。',
      'デプロイはモデルを本番環境へ展開する作業であり、アノテーションとは異なります。'
    ]
  },
  {
    question: 'データ前処理における「外れ値（Outlier）」の扱いとして適切でないものはどれか。',
    options: [
      'ドメイン知識に基づいて外れ値を除去する',
      'IQR法（四分位範囲）を用いて外れ値を検出・除去する',
      '外れ値を含めたまま何も処置せずにモデルに学習させる',
      'ロバストなモデル（外れ値の影響を受けにくいアルゴリズム）を選択する'
    ],
    correctAnswer: 2,
    explanation: '外れ値を何も処置しないままモデルに学習させると、外れ値がモデルに強く影響し、汎化性能が低下する恐れがあります。外れ値はドメイン知識や統計的手法で検出し、除去・置換・ロバストモデルの採用など適切に対処する必要があります。',
    optionExplanations: [
      'ドメイン知識による除去は外れ値への適切なアプローチです。例：センサーエラーによる異常値の除去。',
      'IQR法など統計的手法による外れ値の検出・除去は標準的な前処理です。',
      '正解（適切でないもの）。外れ値を無処置のままにするとモデルの精度・汎化性能に悪影響を与えます。',
      'ロバストなモデル選択は外れ値への有効な対処法の一つです。'
    ]
  },
  {
    question: '欠損値（Missing Value）の処理方法として適切でないものはどれか。',
    options: [
      '欠損値を列の平均値や中央値で補完する（imputation）',
      '欠損値が多すぎる列や行を削除する',
      '欠損値を\"欠損\"を示す特別な値（例：-9999など）で置き換えてモデルに学習させる',
      '欠損値が存在するデータを全データの中に均等に分散させて、モデルが欠損を学習しないようにする'
    ],
    correctAnswer: 3,
    explanation: '欠損値を均等に分散させることはデータの意味を保持しながら欠損を隠す操作で、モデルが欠損パターンを正しく学習できず適切ではありません。平均・中央値補完、行/列削除、または専用機能（欠損値を直接扱えるアルゴリズム）などが有効です。',
    optionExplanations: [
      '平均値や中央値でのimputationはデータの分布を大きく崩さずに補完できる標準的な手法です。',
      '欠損割合が高い列や行の削除も、残りのデータクオリティを保つ有効な方法です。',
      '特殊な値で置換してモデルに学習させることもアプローチとして用いられます。',
      '正解（適切でないもの）。欠損値を均等分散させることは、データに人為的な歪みを作るため不適切です。'
    ]
  },
  {
    question: 'データ収集時における「データの代表性」の問題（サンプリングバイアス）の説明として正しいものはどれか。',
    options: [
      '収集したデータが多すぎて、モデルの学習時間が過度に長くなる問題',
      '収集したデータが現実の対象母集団を適切に反映しておらず、偏ったモデルが生まれる問題',
      '収集したデータのファイル形式が統一されていない問題',
      '収集コストが高すぎてプロジェクト予算を超過する問題'
    ],
    correctAnswer: 1,
    explanation: 'サンプリングバイアスとは、収集したデータが実際の母集団（現実の分布）を正確に反映していないことです。例えば、特定の人種・性別・年齢層のデータだけで学習すると、偏ったAIシステムが生まれます。',
    optionExplanations: [
      'データ量の問題は計算リソースの課題であり、サンプリングバイアスとは異なります。',
      '正解。サンプリングバイアスは収集データが母集団を代表していないことで生じる偏りの問題です。',
      'ファイル形式の不統一はデータ前処理の問題であり、サンプリングバイアスとは異なります。',
      'コスト超過はプロジェクト管理の問題であり、データの代表性の問題とは無関係です。'
    ]
  },
  {
    question: '特徴量エンジニアリング（Feature Engineering）の説明として最も正確なものはどれか。',
    options: [
      'AIシステムのユーザーインターフェースを設計する作業',
      '生データからモデルの学習に有効な入力変数（特徴量）を選択・変換・作成する作業',
      '機械学習モデルのハイパーパラメータを最適化する作業',
      'AIプロジェクトの要件定義書を作成する作業'
    ],
    correctAnswer: 1,
    explanation: '特徴量エンジニアリングとは、ドメイン知識や分析を活用して、生データから機械学習モデルの予測精度を高める特徴量（入力変数）を選択・加工・新規作成する作業です。モデルの性能に大きく影響します。',
    optionExplanations: [
      'UIの設計はフロントエンド開発の話であり、特徴量エンジニアリングとは無関係です。',
      '正解。特徴量エンジニアリングはモデルの入力変数を改善するための重要な前処理作業です。',
      'ハイパーパラメータ最適化はモデルチューニングの作業であり、特徴量エンジニアリングとは別です。',
      '要件定義書の作成はプロジェクト管理の活動であり、特徴量エンジニアリングとは異なります。'
    ]
  },
  {
    question: 'AI開発において「データパイプライン」が指すものとして最も適切なものはどれか。',
    options: [
      'AIモデルが画像データを処理する際の物理的な通信回線',
      'データ収集・前処理・変換・保存などの一連のデータ処理フローを自動化したシステム',
      'AIシステムのAPIエンドポイントをまとめた設計書',
      'データセンター間をつなぐ物理的なネットワーク回線'
    ],
    correctAnswer: 1,
    explanation: 'データパイプラインとは、データの収集・クレンジング・変換・加工・保存・配信などの一連の処理を自動化・効率化した仕組みです。品質の高いデータを安定的に供給するためにAIシステムに不可欠です。',
    optionExplanations: [
      '物理的な通信回線はネットワーク用語であり、データパイプラインの意味ではありません。',
      '正解。データパイプラインはデータ処理の一連のフローを自動化・効率化した仕組みです。',
      'API設計書はシステム設計ドキュメントであり、データパイプラインとは異なります。',
      'データセンター間の物理回線はネットワークインフラの話であり、データパイプラインとは別です。'
    ]
  },
  {
    question: 'AIプロジェクトにおける「ラベルノイズ」の説明として正しいものはどれか。',
    options: [
      'AIシステムが音声データを処理する際に生じる背景雑音のこと',
      '学習データのアノテーション（ラベル）が誤っている、または一貫性がない状態',
      'ネットワーク通信における遅延や乱れのこと',
      '画像データに意図的にノイズを加えてデータ拡張する手法'
    ],
    correctAnswer: 1,
    explanation: 'ラベルノイズとは、教師あり学習の学習データにおいて、人手によるアノテーションミスや基準の不統一などにより、正解ラベルが誤っている・矛盾しているデータが混在している状態です。モデルの性能低下の大きな原因になります。',
    optionExplanations: [
      '音声の背景雑音は音声処理の分野での概念であり、ラベルノイズとは異なります。',
      '正解。ラベルノイズはアノテーションの誤りや不一致によりラベルの品質が低下している状態です。',
      'ネットワーク遅延はインフラの問題であり、ラベルノイズとは無関係です。',
      'データ拡張でのノイズ付加は「ノイズ注入（Noise Injection）」であり、ラベルノイズとは別の概念です。'
    ]
  },
  {
    question: '機械学習において「学習データ・検証データ・テストデータ」の分割の説明として正しいものはどれか。',
    options: [
      '学習データと検証データは同じデータで、テストデータのみを別途用意する',
      '学習データ：モデルの学習用、検証データ：ハイパーパラメータ調整用、テストデータ：最終的な性能評価用',
      '3種類のデータは同じデータセットを複製したものであり、どれを使っても結果は同じである',
      '学習データは推論時の入力データであり、検証データは学習後の重みを指す'
    ],
    correctAnswer: 1,
    explanation: '学習データはモデルの重みを更新するために使い、検証データは学習中にハイパーパラメータ調整や過学習チェックに使い、テストデータは最終的な汎化性能の評価のために（一度だけ）使います。3つは役割が明確に異なります。',
    optionExplanations: [
      '学習データと検証データは必ず異なるデータを使う必要があります。同じデータでは過学習を検出できません。',
      '正解。それぞれのデータセットの役割が正しく説明されています。',
      '3つのデータは独立して分離されており、同一データの複製ではありません。',
      '学習データとモデルの重みは全く異なる概念です。'
    ]
  },
  {
    question: 'AIプロジェクトにおいて「データガバナンス」が重要な理由として最も適切なものはどれか。',
    options: [
      'AIシステムの処理速度を向上させるため',
      'データの品質・セキュリティ・プライバシー・利用方針を組織的に管理し、信頼できるAI開発の基盤を整えるため',
      'AIモデルのパラメータ数を管理するため',
      'ディープラーニングモデルの学習率を自動調整するため'
    ],
    correctAnswer: 1,
    explanation: 'データガバナンスとは、組織が保有するデータの品質・整合性・セキュリティ・プライバシー・利用規則などを組織横断的に定義・管理する仕組みです。AIシステムの信頼性・公平性・法令遵守の基盤となります。',
    optionExplanations: [
      '処理速度の向上は最適化・インフラの課題であり、データガバナンスの主目的ではありません。',
      '正解。データガバナンスはデータ品質・セキュリティ・倫理・法令遵守を組織的に管理する枠組みです。',
      'パラメータ管理はモデルアーキテクチャの話であり、データガバナンスとは異なります。',
      '学習率の自動調整はモデルの最適化手法の話です。'
    ]
  },
  {
    question: 'クラウド上のAI開発において「AutoML」を活用することの主なメリットはどれか。',
    options: [
      'AIシステムのセキュリティが完全に保証される',
      '機械学習の専門知識が少ない利用者でも、モデル選択やハイパーパラメータ調整を自動化できる',
      'データ収集のコストがゼロになる',
      '作成したモデルの著作権が自動的に保護される'
    ],
    correctAnswer: 1,
    explanation: 'AutoMLはモデルの選択・特徴量エンジニアリング・ハイパーパラメータ調整などのプロセスを自動化するサービスです。深い機械学習の専門知識がなくても高精度モデルを構築しやすくなります。Google AutoML、Azure AutoML等が代表例です。',
    optionExplanations: [
      'AutoMLはモデル構築の自動化であり、セキュリティを保証するものではありません。',
      '正解。AutoMLは機械学習プロセスの自動化により、専門知識の少ない人でも活用できることが主なメリットです。',
      'AutoMLはモデル構築の自動化であり、データ収集コストには直接関係しません。',
      '著作権はAutoMLの機能とは無関係です。AIが生成したモデルの権利は別途法的に検討が必要です。'
    ]
  },
  {
    question: 'AIシステム開発における「CI/CD（継続的インテグレーション/継続的デリバリー）」の目的として正しいものはどれか。',
    options: [
      'AIモデルの学習アルゴリズムを自動的に改良すること',
      'コードの変更を自動的にテスト・ビルド・デプロイし、品質を保ちながら迅速にリリースできる環境を整えること',
      'データセンターのサーバーを自動的に物理的にメンテナンスすること',
      'AIシステムのエンドユーザーを自動的に認証すること'
    ],
    correctAnswer: 1,
    explanation: 'CI/CDはソフトウェア開発の自動化プラクティスです。CI（継続的インテグレーション）はコード変更を自動的にテストし、CD（継続的デリバリー）は自動でステージング環境や本番環境へデプロイします。MLOpsではモデルの再学習・評価・デプロイにも適用されます。',
    optionExplanations: [
      'CI/CDはソフトウェアのリリースパイプラインの自動化であり、アルゴリズム改良とは異なります。',
      '正解。CI/CDはコードの変更からテスト・デプロイまでを自動化し、迅速かつ安全なリリースを実現します。',
      'サーバーの物理的メンテナンスは運用インフラの話であり、CI/CDとは無関係です。',
      'ユーザー認証はセキュリティの話であり、CI/CDの目的ではありません。'
    ]
  },
  {
    question: 'AIシステムのA/Bテストの説明として正しいものはどれか。',
    options: [
      'AIのA（強いAI）とB（弱いAI）の2種類を比較する分類方法',
      '2種類の異なるモデルやシステム（AとB）を実際のユーザーに並行して提供し、どちらが優れているかを比較評価する手法',
      'AIシステムのソースコードをAとBの2人のエンジニアが交互にレビューする手法',
      'AIモデルの学習データをA（訓練用）とB（テスト用）に分割する手法'
    ],
    correctAnswer: 1,
    explanation: 'A/Bテストは、異なるバージョンのシステムやモデル（AとB）を同時に実際のユーザーに提供し、クリック率・成約率・精度などのビジネス/技術指標を比較してより優れた方を採択するための実験手法です。',
    optionExplanations: [
      'A=強いAI、B=弱いAIという分類はA/Bテストとは全く関係ありません。',
      '正解。A/Bテストは2バージョンを実ユーザーに並行提供して優劣を比較評価する手法です。',
      'コードレビューの方法論ではなく、ユーザー向けの実験手法がA/Bテストです。',
      'データ分割はホールドアウト法や交差検証の話であり、A/Bテストとは区別されます。'
    ]
  },
  {
    question: 'データ収集においてWebスクレイピングを行う際に遵守すべき事項として誤っているものはどれか。',
    options: [
      'サイトのrobots.txtを確認し、スクレイピングを禁止しているページにはアクセスしない',
      'サーバーへの過度なリクエスト送信（DoS的な行為）を行わない',
      '取得したデータに著作権が発生する場合があることを考慮する',
      'ログインが必要なサイトは、任意のアカウントでログインしてデータを取得することが常に許可されている'
    ],
    correctAnswer: 3,
    explanation: 'ログインが必要なサイトのデータは、利用規約や不正アクセス禁止法の観点から、必ずしも自由に取得できるわけではありません。許可なく他者のアカウントを使ったり、利用規約に違反してデータを取得することは違法行為になりえます。',
    optionExplanations: [
      'robots.txtの遵守はWebスクレイピングのエチケット・法的要件として重要です。',
      'サーバーへの過剰リクエストはDDoS攻撃に類する行為になりえるため避けるべきです。',
      '著作権への配慮はデータ収集時に常に必要な考慮事項です。',
      '正解（誤っているもの）。ログイン必須サイトへのアクセスは利用規約や不正アクセス禁止法の制約を受けます。'
    ]
  },
  {
    question: '合成データ（Synthetic Data）の活用目的として最も適切なものはどれか。',
    options: [
      '既存のAIモデルのソースコードを自動生成すること',
      'プライバシー保護や実データ不足を補うために、統計的性質を持つ人工的に生成されたデータを学習に活用すること',
      'AIシステムのUIデザインを自動生成すること',
      'ユーザーの購買データを匿名化せずにそのまま活用すること'
    ],
    correctAnswer: 1,
    explanation: '合成データとは、実際のデータを元にGANや統計的手法で人工的に生成したデータです。実データへのアクセスが難しい（医療・金融など）場合や、特定のシナリオのデータが不足している場合に学習データを補完するために活用されます。',
    optionExplanations: [
      'ソースコードの自動生成はコード生成AIの話であり、合成データとは異なります。',
      '正解。合成データはプライバシー保護・データ不足補完を目的とした人工生成データです。',
      'UIデザインの自動生成はデザインAIの話であり、合成データとは無関係です。',
      '匿名化せずにデータを活用することはプライバシー侵害になりえます。合成データはその逆の発想です。'
    ]
  },
  {
    question: 'AIシステムの評価において「オフライン評価」と「オンライン評価」の違いとして正しいものはどれか。',
    options: [
      'オフライン評価はインターネット接続なしで行い、オンライン評価はクラウド上で行う',
      'オフライン評価は保留テストデータで行い、オンライン評価は実際のユーザー・環境でA/Bテスト等を通じて行う',
      'オフライン評価はモデルが古い、オンライン評価はモデルが新しいことを意味する',
      'オフライン評価はデータサイエンティストが行い、オンライン評価はビジネス部門が行う'
    ],
    correctAnswer: 1,
    explanation: 'オフライン評価はモデル開発段階でテストデータセットを使って精度指標（Accuracy、F値など）を測定します。オンライン評価は本番環境に実際にデプロイし、リアルユーザーのインタラクション（CTR改善など）を通じてビジネス指標で評価します。',
    optionExplanations: [
      'インターネット接続の有無がオフライン/オンラインの区別ではありません。',
      '正解。テストデータによる開発時評価がオフライン、実環境での実ユーザーを使った評価がオンラインです。',
      'モデルの新旧とオフライン/オンラインは関係ありません。',
      '評価を行う担当者の違いが定義ではありません。'
    ]
  },
];

async function migrate() {
  const client = await pool.connect();
  try {
    console.log('=== G検定 カテゴリ マイグレーション開始 ===\n');

    // -----------------------------------------------
    // STEP 1: Rename categories
    // -----------------------------------------------
    console.log('【STEP 1】カテゴリ名の更新...');
    for (const r of RENAMES) {
      if (r.oldId === r.newId) {
        // Just update title and displayorder
        await client.query(
          `UPDATE g_kentei_categories SET title=$1, displayorder=$2 WHERE id=$3`,
          [r.title, r.displayorder, r.oldId]
        );
        console.log(`  ✅ displayorder更新: ${r.oldId} → order=${r.displayorder}`);
      } else {
        // Insert new row
        await client.query(
          `INSERT INTO g_kentei_categories (id, title, icon, color, bg, displayorder)
           VALUES ($1,$2,$3,$4,$5,$6)
           ON CONFLICT (id) DO UPDATE SET title=$2, icon=$3, color=$4, bg=$5, displayorder=$6`,
          [r.newId, r.title, r.icon, r.color, r.bg, r.displayorder]
        );
        // Move questions
        const moved = await client.query(
          `UPDATE g_kentei_questions SET category=$1 WHERE category=$2`,
          [r.newId, r.oldId]
        );
        // Delete old category
        await client.query(`DELETE FROM g_kentei_categories WHERE id=$1`, [r.oldId]);
        console.log(`  ✅ リネーム: "${r.oldId}" → "${r.newId}" (問題: ${moved.rowCount}件移動)`);
      }
    }

    // -----------------------------------------------
    // STEP 2: Add new category
    // -----------------------------------------------
    console.log('\n【STEP 2】新カテゴリ追加...');
    await client.query(
      `INSERT INTO g_kentei_categories (id, title, icon, color, bg, displayorder)
       VALUES ($1,$2,$3,$4,$5,$6)
       ON CONFLICT (id) DO UPDATE SET title=$2, icon=$3, color=$4, bg=$5, displayorder=$6`,
      [NEW_CATEGORY.id, NEW_CATEGORY.title, NEW_CATEGORY.icon, NEW_CATEGORY.color, NEW_CATEGORY.bg, NEW_CATEGORY.displayorder]
    );
    console.log(`  ✅ 新カテゴリ追加: "${NEW_CATEGORY.title}" (order=${NEW_CATEGORY.displayorder})`);

    // -----------------------------------------------
    // STEP 3: Insert new questions
    // -----------------------------------------------
    console.log('\n【STEP 3】新カテゴリ問題を追加中...');
    let added = 0;
    for (const q of NEW_QUESTIONS) {
      await client.query(
        `INSERT INTO g_kentei_questions (category, question, options, correctAnswer, explanation, optionExplanations, source)
         VALUES ($1,$2,$3,$4,$5,$6,$7)`,
        [
          NEW_CATEGORY.id,
          q.question,
          JSON.stringify(q.options),
          q.correctAnswer,
          q.explanation,
          JSON.stringify(q.optionExplanations),
          'system'
        ]
      );
      added++;
      process.stdout.write(`\r  追加中... ${added}/${NEW_QUESTIONS.length}`);
    }
    console.log(`\n  ✅ ${added}問追加完了`);

    // -----------------------------------------------
    // Verification
    // -----------------------------------------------
    console.log('\n=== 最終確認 ===');
    const cats = await client.query(
      `SELECT c.id, c.title, c.displayorder, COUNT(q.id) as cnt
       FROM g_kentei_categories c
       LEFT JOIN g_kentei_questions q ON q.category = c.id
       GROUP BY c.id, c.title, c.displayorder
       ORDER BY c.displayorder ASC`
    );
    cats.rows.forEach(c => {
      console.log(`  #${parseInt(c.displayorder)+1} | ${c.title} | ${c.cnt}問`);
    });

    const total = await client.query('SELECT COUNT(*) as cnt FROM g_kentei_questions');
    console.log(`\n合計: ${total.rows[0].cnt}問`);
    console.log('\n✅ マイグレーション完了！');

  } catch (err) {
    console.error('❌ エラー:', err.message);
    throw err;
  } finally {
    client.release();
    await pool.end();
  }
}

migrate();
