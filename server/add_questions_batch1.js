import pkg from 'pg';
const { Pool } = pkg;
const pool = new Pool({ connectionString:'postgresql://g_kentei_prep_app_db_user:0vZFHekJvsuMexPcBCKx5Ix4Noy7WZJO@dpg-d63nv6cr85hc73bckig0-a.oregon-postgres.render.com/g_kentei_prep_app_db', ssl:{rejectUnauthorized:false} });

const LAW = 'AIに関する法律と契約';
const ETHICS = 'AI倫理・AIガバナンス';

const questions = [
  // ===== 法律 =====
  { cat: LAW, q:'個人情報保護法において「個人情報」の定義として正しいものはどれか。', opts:['企業が保有するすべてのデータ','生存する個人に関する情報で、特定の個人を識別できるもの','インターネット上に公開された情報すべて','金融機関が管理する財務データ'], ans:1, exp:'個人情報保護法上の個人情報とは、生存する個人に関する情報で、氏名・生年月日等により特定の個人を識別できるものを指します。', optExp:['企業データ全般は個人情報とは限りません。','正解。生存個人に関し特定の個人を識別できる情報です。','公開された情報も個人情報になりえますが、定義はこれではありません。','財務データ限定ではありません。'] },
  { cat: LAW, q:'著作権法において、AIが学習のためにデータを収集・利用することについて、2019年の法改正で認められた例外規定はどれか。', opts:['AIの利用目的であればすべてのデータを無制限に利用できる','情報解析の用に供する場合は著作権者の許諾なく複製等が可能','学術目的であれば商用データも自由に利用できる','政府機関のAIのみ著作権の適用が免除される'], ans:1, exp:'2019年の著作権法改正により、情報解析（機械学習等）を目的とする場合は、著作権者の許諾なしにデータを複製・利用できる例外規定（第30条の4）が整備されました。', optExp:['無制限ではなく「情報解析目的」という条件があります。','正解。情報解析目的の複製等は著作権者の許諾不要とされました。','商用・学術の区別ではなく「情報解析目的」が要件です。','政府機関限定ではありません。'] },
  { cat: LAW, q:'機械学習モデルの学習に使用したデータセットの著作権に関して正しい説明はどれか。', opts:['学習に使用したデータセットの著作権は自動的にAI開発者に移転する','データセット自体は創作性があれば著作権の保護対象となりうる','AIが生成したコンテンツは常に著作権が発生する','学習データの著作権はモデルを公開した時点で消滅する'], ans:1, exp:'データベースやデータセットも、素材の選択や配列に創作性があれば「データベースの著作物」として著作権保護を受けます（著作権法第12条の2）。', optExp:['開発者への自動移転はありません。','正解。創作性のあるデータセットは著作権保護対象です。','AI生成物の著作権については現行法では明確でなく、常に発生するわけではありません。','公開によって著作権は消滅しません。'] },
  { cat: LAW, q:'不正競争防止法における「限定提供データ」の保護について正しいものはどれか。', opts:['誰でも自由にアクセスできるオープンデータを保護する','業として特定の者に提供する電磁的方法で管理されたデータを不正取得等から保護する','個人の日記や日常の記録を保護する','AIが生成したすべてのアウトプットを保護する'], ans:1, exp:'2019年の不正競争防止法改正により「限定提供データ」が保護対象に追加されました。業として特定の者に電磁的方法で提供・管理するデータの不正取得・使用・開示を禁止します。', optExp:['オープンデータは限定提供データに該当しません。','正解。業として特定の者に提供・管理するデータが保護対象です。','個人の日記は対象外です。','AI生成物は限定提供データの定義に含まれません。'] },
  { cat: LAW, q:'AI開発委託契約で「成果物の知的財産権の帰属」を明確にすることが重要な理由として最も適切なものはどれか。', opts:['AIモデルは必ず発注者に帰属することが法律で定められているから','契約で明示しなければ、受託者（開発者）に権利が残る可能性があるから','AIモデルには著作権は発生しないから','知的財産権は国に帰属するものだから'], ans:1, exp:'日本の著作権法では、職務著作の要件を満たさない限り、著作物は創作者（受託者）に帰属します。AI開発委託では契約上で明示的に知財の帰属を定めなければ、受託者に権利が残るリスクがあります。', optExp:['法律で発注者帰属が定められているわけではありません。','正解。契約で明示しなければ受託者（開発会社）に権利が残る可能性があります。','AIモデルには著作権が発生しうる場合があります。','知的財産権は原則として創作者に帰属します。'] },
  { cat: LAW, q:'GDPRとはどのような規制か。', opts:['日本の個人情報保護法の別称','EU域内の個人データ保護に関する包括的な規則で、違反には高額制裁金が科される','米国のAI産業を規制するための法律','中国のサイバーセキュリティに関する法律'], ans:1, exp:'GDPR（一般データ保護規則）はEUが2018年に施行した個人データ保護法で、EU市民の個人データを処理する企業に適用され、違反時には全世界年間売上の4%または2000万ユーロのいずれか高い方が制裁金として科されます。', optExp:['日本の個人情報保護法とは別の規制です。','正解。EU域内の個人データ保護規則で高額制裁金が特徴です。','米国の法律ではなくEUの規制です。','中国の法律ではありません。'] },
  { cat: LAW, q:'特許法においてAI関連の発明が特許を取得するための主な要件として正しいものはどれか。', opts:['AIが自律的に生成したアイデアは自動的に特許を取得できる','新規性・進歩性・産業上の利用可能性を満たした発明として出願する必要がある','ソフトウェアは特許の対象外である','AIシステムはすべて営業秘密として保護される'], ans:1, exp:'特許を取得するには①新規性（既存技術と異なる）②進歩性（当業者が容易に想到できない）③産業上の利用可能性の三要件を満たす必要があります。AIが生成した発明でも、人間が発明者として出願することで保護を受けられる場合があります。', optExp:['AIが自律的に生成したものは現行法では発明者になれません。','正解。新規性・進歩性・産業上の利用可能性が特許要件です。','ソフトウェアも一定条件で特許の対象になります。','営業秘密は不正競争防止法で保護されますが、特許とは別の保護手段です。'] },
  { cat: LAW, q:'AIサービス提供契約において「免責条項」が重要な理由として最も適切なものはどれか。', opts:['免責条項があれば、いかなる損害も法的責任を免れる','AIシステムの予測誤りや出力の誤りによる損害について、サービス提供者の責任範囲を明確にするため','免責条項はユーザーを保護するためのものである','免責条項がなければAIサービスは提供できない'], ans:1, exp:'AIシステムは完全な精度を保証できないため、予測誤りや想定外の出力による損害のリスクがあります。免責条項でサービス提供者の責任範囲を契約上明確にし、法的リスクを管理することが重要です。', optExp:['免責条項があっても故意・重過失による損害は責任を免れない場合があります。','正解。AIの誤り・欠陥による損害に対する責任範囲を明確化するためです。','免責条項は主にサービス提供者を保護するものです。','免責条項なしでも提供できますが、リスク管理のために重要です。'] },
  { cat: LAW, q:'AI開発契約における「データの所有権」に関して正しい説明はどれか。', opts:['データは物権的な所有権の対象であるため、契約がなくても権利は明確である','日本法上データ自体に所有権は認められていないため、契約で利用権の範囲を明確にすることが重要','すべてのデータは国家が管理する公共財である','データの所有権はデータを入力した者に自動的に発生する'], ans:1, exp:'日本の民法ではデータ自体を「物」として所有権の対象とする規定がないため、データに対して物権的な所有権は認められていません。そのため、AI開発契約でデータの利用権・利用目的・範囲等を明確に定めることが不可欠です。', optExp:['日本法上データに所有権はなく、契約がないと権利関係が不明確になります。','正解。データには所有権がないため、契約での利用権の明確化が重要です。','データは国家の公共財ではありません。','入力者への自動的な権利発生は日本法上認められていません。'] },
  { cat: LAW, q:'「AIと独占禁止法」に関して正しいものはどれか。', opts:['AIを利用した企業間のデータ共有はすべて独占禁止法違反となる','AIを活用した価格カルテル（競合他社との価格協調行為）も独占禁止法の規制対象となりうる','AIシステムは独占禁止法の適用外である','データ量が多い企業のAI利用はすべて市場支配的地位の濫用にあたる'], ans:1, exp:'AIを使って競合他社と価格等を調整するアルゴリズム共謀（Algorithmic Collusion）は、人間が直接合意していなくても独占禁止法（私的独占・不当な取引制限）の規制対象となりうると各国の競争当局が警告しています。', optExp:['データ共有すべてが違反ではなく、競争制限的な効果があるかが判断基準です。','正解。AIによるアルゴリズム共謀も独占禁止法の対象となりえます。','AIシステムも独占禁止法の適用を受けます。','データ量だけで市場支配的地位の濫用にはなりません。'] },
  // ===== 倫理 =====
  { cat: ETHICS, q:'AIの「説明可能性（Explainability）」が重要とされる主な理由はどれか。', opts:['AIの処理速度を向上させるため','AIが下した判断の根拠をユーザーや関係者が理解・検証できるようにするため','AIのソースコードをオープンソースにするため','AIシステムの消費電力を削減するため'], ans:1, exp:'AIシステム（特にディープラーニング）はブラックボックスになりやすく、なぜその判断をしたのかが不明確です。医療・金融・採用など重要な意思決定にAIを使う場合、その根拠を説明できることが信頼・倫理・法的要件（EUのAI法など）上不可欠です。', optExp:['説明可能性は処理速度と無関係です。','正解。判断根拠の理解・検証を可能にすることが説明可能性の目的です。','オープンソース化は説明可能性とは別の話です。','消費電力削減は環境問題への対応であり、説明可能性とは異なります。'] },
  { cat: ETHICS, q:'AIシステムにおける「公平性（Fairness）」の問題として代表的な事例はどれか。', opts:['AIモデルの学習時間が長くなること','採用選考AIが特定の性別・人種に不利な判断をするバイアスを持つこと','AIシステムの応答速度が遅いこと','AIモデルのファイルサイズが大きいこと'], ans:1, exp:'AIモデルは学習データに含まれる偏り（バイアス）を学習・増幅させることがあります。例えば過去の採用データが特定の属性に偏っていれば、AIも同じ偏りで判断し差別的な結果を生む可能性があります。', optExp:['学習時間はパフォーマンスの問題であり、公平性とは無関係です。','正解。学習データのバイアスによる差別的判断がAIの公平性問題の典型例です。','応答速度はシステム性能の問題です。','モデルサイズは効率の問題です。'] },
  { cat: ETHICS, q:'AI倫理における「アカウンタビリティ（説明責任）」の説明として正しいものはどれか。', opts:['AIシステムの開発コストを公開する義務','AIの判断・行動に対して責任主体が説明・釈明できる状態を確保すること','AIモデルのパラメータ数を公表すること','AI会社の財務情報を開示すること'], ans:1, exp:'アカウンタビリティとは、AIシステムがとった行動や判断について、誰が責任を持つのかを明確にし、その行動の理由を説明できる状態です。AI倫理のガイドラインや規制において中心的概念のひとつです。', optExp:['開発コストの公開は財務開示の話であり、アカウンタビリティの核心ではありません。','正解。責任主体が判断・行動を説明できる状態の確保がアカウンタビリティです。','パラメータ数の公表は透明性の一側面ですが、アカウンタビリティの定義ではありません。','財務情報の開示はコーポレートガバナンスの話です。'] },
  { cat: ETHICS, q:'「AIガバナンス」とはどのような概念か。', opts:['AIエンジニアの給与を管理するための人事制度','組織がAIを責任ある形で開発・利用するためのルール・体制・プロセスの整備','AIシステムのサーバーを物理的に管理する活動','政府がAI企業を買収・統治すること'], ans:1, exp:'AIガバナンスとは、AI技術を倫理的・法的・社会的に適切な形で開発・運用するための組織内ルール、意思決定体制、リスク管理プロセス、監視体制などを整備・運用する取り組みです。', optExp:['人事制度はAIガバナンスとは無関係です。','正解。責任ある形でAIを開発・利用するためのルール・体制・プロセスの整備です。','サーバー管理はインフラ管理であり、AIガバナンスとは異なります。','政府によるAI企業の買収はAIガバナンスの定義ではありません。'] },
  { cat: ETHICS, q:'プライバシーバイデザイン（Privacy by Design）の原則として正しいものはどれか。', opts:['個人情報はユーザーから要求があった場合のみ削除する','プライバシー保護をシステムの設計段階から組み込む考え方','プライバシーポリシーを長文で詳細に記述すること','ユーザーの同意なしにデータを収集できる仕組みを作ること'], ans:1, exp:'プライバシーバイデザインは、プライバシー保護をシステムやビジネスプロセスの設計・開発段階から組み込む考え方（アン・カブキアンが提唱）です。後からプライバシー対策を追加するのではなく、最初から設計に組み込むことが原則です。', optExp:['要求時のみ削除は事後対応であり、プライバシーバイデザインの概念と逆です。','正解。設計段階からプライバシーを組み込む考え方です。','長文ポリシーはプライバシーバイデザインとは異なります。','同意なしのデータ収集はプライバシーバイデザインに反します。'] },
  { cat: ETHICS, q:'EUのAI法（AI Act）のリスクベースアプローチにおいて「許容不可能なリスク」に分類されるAIシステムの例はどれか。', opts:['メール自動分類システム','リアルタイムの公共空間での生体認証（一部例外を除く）','天気予報AI','音楽推薦アルゴリズム'], ans:1, exp:'EU AI Actでは、基本的人権を侵害するリスクが高いシステムを「許容不可能なリスク」として原則禁止しています。法執行目的でのリアルタイム公共空間生体認証がその代表例です。', optExp:['メール分類は低リスクシステムです。','正解。リアルタイム公共空間生体認証は許容不可能なリスクとして原則禁止です。','天気予報AIは低リスクです。','音楽推薦は低リスクシステムです。'] },
  { cat: ETHICS, q:'「フィルターバブル」と呼ばれる現象の説明として正しいものはどれか。', opts:['AIが個人のデータを過度に収集すること','推薦アルゴリズムが個人の好みに合う情報のみを提示し、多様な情報から隔離される現象','AIシステムのバグによってデータが漏洩すること','ニューラルネットワークのレイヤーが多すぎて学習できなくなること'], ans:1, exp:'フィルターバブルはイーライ・パリサーが提唱した概念で、SNSや検索エンジンの推薦アルゴリズムがユーザーの好みに合う情報だけを提示し続けることで、異なる意見や観点の情報に触れにくくなる現象を指します。民主主義への影響が懸念されています。', optExp:['過度なデータ収集はプライバシー問題ですが、フィルターバブルの定義ではありません。','正解。推薦AIが同質の情報のみ提示し多様な情報から切り離される現象です。','データ漏洩はセキュリティ問題です。','学習の失敗は勾配消失問題などの話です。'] },
  { cat: ETHICS, q:'AI倫理において「人間の監督（Human Oversight）」を維持することが重要な理由はどれか。', opts:['AIシステムの処理速度がまだ人間より遅いから','AIが誤った判断や倫理的に問題のある出力をした場合に人間が介入・修正できるようにするため','AIに高額の開発費がかかるから','AIシステムの電力消費を人間が管理するため'], ans:1, exp:'AIシステムは完全ではなく、誤った判断・有害な出力・予期しない動作が起きる可能性があります。重要な意思決定に人間が監督・介入できる体制を持つことで、AIのミスによる被害を最小化し、倫理的・法的責任を確保できます。', optExp:['処理速度はHuman Oversightの理由ではありません。','正解。誤判断・有害出力時の人間介入・修正の確保が目的です。','開発費はHuman Oversightの理由ではありません。','電力管理はHuman Oversightの目的ではありません。'] },
  { cat: ETHICS, q:'AI倫理において「ディープフェイク」が問題視される主な理由はどれか。', opts:['ディープフェイクは多くの計算資源を消費するから','実在の人物の映像・音声を無断で偽造することでプライバシー侵害・詐欺・フェイクニュースに使われるから','ディープフェイクの生成が難しくAI開発者を困らせるから','ディープフェイクはゲーム産業にのみ使用されるから'], ans:1, exp:'ディープフェイクはGANなどを使って実在の人物の偽造映像・音声を生成する技術です。本人の同意なしに偽の映像が作られることでプライバシー侵害、詐欺、性的ハラスメント、フェイクニュースの拡散など深刻な社会問題を引き起こします。', optExp:['計算資源の消費が主な問題ではありません。','正解。無断偽造によるプライバシー侵害・詐欺・フェイクニュースが問題の核心です。','生成の難しさは問題の理由ではありません。','ゲーム産業限定ではなく、悪意ある用途への懸念が問題です。'] },
  { cat: ETHICS, q:'「OECDのAI原則」が定める5つの価値の中に含まれないものはどれか。', opts:['包摂的成長・持続可能な開発・福祉','透明性と説明可能性','AIの最大速度化と低コスト化','安全なAIと強靭性'], ans:2, exp:'OECD AI原則（2019年）の5つの価値は①包摂的成長・持続可能な開発・福祉、②人間中心の価値と公平性、③透明性と説明可能性、④強靭性・安全・セキュリティ、⑤アカウンタビリティです。「速度化・低コスト化」は含まれていません。', optExp:['OECDのAI原則に含まれます。','OECDのAI原則に含まれます。','正解。「最大速度化と低コスト化」はOECDのAI原則に含まれません。','OECDのAI原則に含まれます。'] },
  { cat: ETHICS, q:'「AIウォッシング」の説明として正しいものはどれか。', opts:['AIシステムの外装を定期的に洗浄・メンテナンスすること','実質的なAI倫理への取り組みなしに倫理的・信頼できるAIを標榜するマーケティング行為','AIデータを洗浄（クレンジング）する前処理作業','AIモデルの学習データを匿名化すること'], ans:1, exp:'AIウォッシングとは、実際にはAI倫理への具体的な取り組みが不十分であるにもかかわらず、「倫理的なAI」「信頼できるAI」であるかのように見せかけるマーケティング行為です。グリーンウォッシングのAI版です。', optExp:['物理的な洗浄ではありません。','正解。実質なき倫理的AIの標榜行為がAIウォッシングです。','データクレンジングはデータ前処理の話です。','匿名化はプライバシー保護の手法です。'] },
  { cat: ETHICS, q:'国連のSDGs（持続可能な開発目標）とAIの関係について正しいものはどれか。', opts:['AIはSDGsの達成に一切貢献できない','AIは医療・農業・環境監視等でSDGs達成を加速させる可能性があるが、格差拡大等の負の影響も懸念される','SDGsはAI産業にのみ適用される目標である','AI開発にSDGsの考慮は法律で義務付けられている'], ans:1, exp:'AIはSDGs目標（医療改善・飢餓撲滅・気候変動対策等）の達成を加速させる可能性があります。一方でAI開発による環境負荷（大量電力消費）、雇用置き換え、格差拡大などの負の影響も懸念されており、両面の考慮が必要です。', optExp:['AIはSDGs達成に貢献できる可能性があります。','正解。AIはSDGs達成を加速させる一方、負の影響も懸念されます。','SDGsはAI産業に限定されず、全産業・社会が対象です。','現時点で法律による義務付けはありません。'] },
  { cat: ETHICS, q:'AIシステムにおける「ロバスト性（Robustness）」の説明として最も適切なものはどれか。', opts:['AIモデルのファイルサイズが小さいこと','予期しない入力・攻撃・環境変化があっても安定して正確に動作する能力','AIシステムの開発コストが低いこと','AIが常に同一の出力を返すこと'], ans:1, exp:'AIのロバスト性とは、データの分布変化・ノイズ・敵対的攻撃・想定外の入力などに対しても、性能を維持し安全に動作し続ける能力です。本番運用でのAI信頼性の重要な要素です。', optExp:['ファイルサイズはモデル軽量化の話です。','正解。予期しない状況でも安定・正確に動作できることがロバスト性です。','開発コストはロバスト性と無関係です。','常に同一出力を返すことは決定論的動作であり、ロバスト性の定義ではありません。'] },
];

async function main() {
  const client = await pool.connect();
  try {
    let count = 0;
    for (const q of questions) {
      await client.query(
        `INSERT INTO g_kentei_questions (category,question,options,correctAnswer,explanation,optionExplanations,source) VALUES ($1,$2,$3,$4,$5,$6,'system')`,
        [q.cat, q.q, JSON.stringify(q.opts), q.ans, q.exp, JSON.stringify(q.optExp)]
      );
      count++;
      process.stdout.write(`\r追加中: ${count}/${questions.length}`);
    }
    console.log(`\n✅ ${count}問追加完了`);

    const res = await client.query(`SELECT c.title, COUNT(q.id) as cnt FROM g_kentei_categories c LEFT JOIN g_kentei_questions q ON q.category=c.id WHERE c.id IN ($1,$2) GROUP BY c.title`, [LAW, ETHICS]);
    res.rows.forEach(r => console.log(`  ${r.title}: ${r.cnt}問`));
  } finally {
    client.release();
    await pool.end();
  }
}
main().catch(console.error);
