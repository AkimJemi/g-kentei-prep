# ディープラーニングの応用例

> **G検定対策 勉強ノート** | 分野：DL応用 | 総ページ数：357P | 作成：2026-02-25

---

## 📋 目次

1. 画像処理
2. 画像認識の分野に特化したCNNがよく使用されている
3. 現在のCNNはLeNetの構造をもとに改良したものである
4. 画像処理
5. フィルタ（カーネル）を使って画像の特徴を抽出する層
6. カーネルのサイズをカーネル幅と呼ぶ
7. 画像処理
8. 畳み込み層で出力した特徴マップをルールに従って
9. 画像処理
10. 畳み込み層等で抽出された特徴マップをもとに
11. 目的に応じた値を出力するための層と考えることができる
12. 画像処理
13. CNNの特徴
14. 局所的受容野と重み共有という特徴がある
15. あるユニットに対する入力範囲のこと
16. CNNの特徴
17. CNNの特徴
18. 画像カーネル
19. 特徴マップ
20. CNNの特徴
21. 特定のユニット同士のみが結合しているため局所結合ともいう
22. 各ユニットは次の層の全てのユニットと結合している
23. 次の層の特定のユニットのみと結合している
24. CNNの特徴
25. ズレていても正しく検知できるような性質のこと
26. 判別対象がどこにいても正しく判断できる確率が高い
27. CNNの特徴
28. CNNの特徴
29. 計算量を減らしている
30. CNNの特徴
31. 画像カーネル
32. 特徴マップ
33. 計算量を減らしている
34. CNNの特徴
35. 画像カーネル
36. 特徴マップ
37. データの前処理
38. そのまま学習させるとモデルの性能が悪くなってしまう
39. OpenCVはIntelが開発したライブラリである
40. データの前処理
41. 画像の細かいノイズを除去すること
42. データの前処理
43. 画像の全体のコントラストを調整すること
44. データの前処理
45. ピクセル数
46. 暗明
47. 暗明
48. ピクセル数
49. データの前処理
50. データ拡張

---

## 画像処理

作成者：辻 大貴
- ニューラルネットワーク

---

## 画像認識の分野に特化したCNNがよく使用されている

- CNNの原型となるLeNetの登場以降、数多くのモデルが登場

---

## 現在のCNNはLeNetの構造をもとに改良したものである

- LeNetは、入力層‧畳み込み層‧プーリング層‧全結合層‧
出力層で様々な処理が行われて、結果を出力している

---

## 画像処理

- 畳み込み層

---

## フィルタ（カーネル）を使って画像の特徴を抽出する層

- 基本的にカーネルは画像サイズよりも小さいサイズのものを使う

---

## カーネルのサイズをカーネル幅と呼ぶ

- 畳み込み処理によって得られた2次元データを特徴マップという

---

## 画像処理

- プーリング層

---

## 畳み込み層で出力した特徴マップをルールに従って

小さくしていく層で、重要な情報を残しながら圧縮していく
- ダウンサンプリング、サブサンプリング と言われる
- 圧縮することで計算コストを下げることができる
重みなどはなく、決められた計算を機械的に行っている

---

## 画像処理

- 全結合層

---

## 畳み込み層等で抽出された特徴マップをもとに

---

## 目的に応じた値を出力するための層と考えることができる

- シグモイド関数などを使って目的に応じた値を出力
- 最近ではGAP層が使用されている

---

## 画像処理

---

## CNNの特徴

作成者：辻 大貴
- 畳み込み層

---

## 局所的受容野と重み共有という特徴がある

- 受容野

---

## あるユニットに対する入力範囲のこと

- 入力範囲が局所的なものを局所的受容野という

---

## CNNの特徴

- 局所的受容野

---

## CNNの特徴

1100
1011
0010
0111
110
011
101

---

## 画像カーネル

4

---

## 特徴マップ

- 局所的受容野

---

## CNNの特徴

- 畳み込み層

---

## 特定のユニット同士のみが結合しているため局所結合ともいう

- 一般的なニューラルネットワークは、

---

## 各ユニットは次の層の全てのユニットと結合している

- CNNの畳み込み層やプーリング層のユニットは、

---

## 次の層の特定のユニットのみと結合している

---

## CNNの特徴

- 移動不変性
CNNなどにおいて、入力される画像の物体位置が

---

## ズレていても正しく検知できるような性質のこと

- 局所的な特徴を使用することで位置のずれに強くなる
- 局所的な情報に基づいて判断するため

---

## 判別対象がどこにいても正しく判断できる確率が高い

---

## CNNの特徴

- 移動不変性

---

## CNNの特徴

1100
1011
0010
0111
重み（カーネル）を共有することでパラメータ数を減らし、

---

## 計算量を減らしている

---

## CNNの特徴

110
011
101

---

## 画像カーネル

4

---

## 特徴マップ

1100
1011
0010
0111
重み（カーネル）を共有することでパラメータ数を減らし、

---

## 計算量を減らしている

---

## CNNの特徴

110
011
101

---

## 画像カーネル

43

---

## 特徴マップ

---

## データの前処理

作成者：辻 大貴
- データの前処理
画像データにはノイズなどがあり、

---

## そのまま学習させるとモデルの性能が悪くなってしまう

- ノイズなどを取り除きデータの質を高めることが大切（前処理）
- 画像処理や画像解析ではOpenCVがよく使用される

---

## OpenCVはIntelが開発したライブラリである

---

## データの前処理

- データの前処理
- 平滑化

---

## 画像の細かいノイズを除去すること

- グレースケール化
画像の色を白や黒、その中間の色で表現すること
- カラー情報が不要なときに使用される（計算コストの低下）

---

## データの前処理

- データの前処理
- ヒストグラム平坦化

---

## 画像の全体のコントラストを調整すること

- 画像の明暗を平均化することで鮮明な画像に変換できる

---

## データの前処理

---

## ピクセル数

---

## 暗明

---

## 暗明

---

## ピクセル数

- データの前処理
- ヒストグラム平坦化

---

## データの前処理

---

## データ拡張

作成者：辻 大貴
- データの拡張

---

## 精度の高いモデルを作っていくためには

---

## データのバリエーションを豊富にする必要がある

- 物体の角度、光の当たり方など様々なバリエーションが必要
- 多種多様なデータを収集することはコスト面から難しい

---

## 数万のデータを収集するために数年かかってしまう場合もある

---

## データの拡張

- データの拡張
既存の画像データを加工して、別の画像データを

---

## 生成していくという方法がよく使われる（水増し）

- コントラストを変更、左右逆転させる など
- 多種多様なデータをモデルに学習させることで

---

## ロバスト性を高めることができる

---

## データの拡張

- データの拡張
- ロバスト性

---

## 外部の環境の影響を受けにくいという性質のこと

- 多種多様なデータを学習することで

---

## ノイズなどのあるデータがあったとしても正しく予測できる

---

## データの拡張

- データの拡張

---

## データのバリエーションを豊富にすることは大切だが

---

## 現実に存在しないデータなどを生成しても意味がない

- 現実味のあるデータを生成して学習させることが大切
- 「6」を学習させるためにデータを生成しているとき、

---

## 「6」を180度回転させたデータを生成するのは不適切

---

## データの拡張

- Cutout

---

## 画像の一部の領域をランダムにマスク処理する手法

- マスクのサイズは固定で、画素値は0や画像の平均値を使用
- マスク処理

---

## 画像データの一部を隠すような処理のこと

- 画像データの一部を画素値を0にするなどの処理を行う

---

## データの拡張

- Cutout

---

## 画像の一部の領域をランダムにマスク処理する手法

---

## データの拡張

- Random Erasing

---

## 画像の一部をランダムにマスク処理する手法

---

## データの拡張

- Cutout

---

## ランダムにマスク処理（正方形領域）を行う

- Random Erasing

---

## 領域サイズを含めてランダムにマスク処理を行う

- マスク（画像を覆い隠すもの）は⻑方形であり固定でない

---

## データの拡張

- Mixup

---

## 2枚の画像を合成して新しい画像を生成する手法

---

## データの拡張

- CutMix

---

## CutoutとMixupを組み合わせた手法

---

## データの拡張

- アフィン変換
平行移動や線形変換（画像の拡大や縮小、回転など）を

---

## 組み合わせた変換方法

---

## データの拡張

- Random Flip
画像をランダムに水平方向や垂直方向に回転させて、

---

## 画像を変換させる手法のこと

---

## データの拡張

- コントラスト
画像の明暗などの差のこと、コントラストを高くすると、
明暗の差が大きくなり、低くすると明暗の差が小さくなる

---

## データの拡張

- 輝度
画像の明るさの度合いのことで、輝度を高くすると、
画像全体が明るくなり、低くすると画像全体が暗くなる

---

## データの拡張

- 切り抜き（crop）

---

## 画像の一部分を切り取ることである

---

## データの拡張

- ノイズ

---

## 画像にノイズを追加すること

---

## データの拡張

- RandAugment

---

## 複数の拡張操作をランダムに実施する手法のこと

- 拡張の大きさ（強度）を変更することも可能
- paraphrasing

---

## テキストデータ内の単語等に対して様々な言い換えを行うこと

- 落ちたコップを持ち上げる ⇨ 落ちたコップを拾う

---

## データの拡張

水増ししたデータを全て保存すると、容量が大きくなる
- 1万の画像データからそれぞれ10種類のデータを

---

## 生成すると画像データは10万データになってしまう

- 画像データから数十や数百のデータを取り出し、
データを拡張し、拡張したデータをもとに学習を行う

---

## データの拡張

---

## 画像認識分野

---

## （物体認識①）

作成者：辻 大貴
- 物体認識

---

## 入力された画像に何があるのかを識別する

- 「りんご」が画像を入力して、「りんご」と出力される
- 実際は各クラスの確信度（確率）をもとに

---

## 最も確信度の高いと思われるクラスが出力されている

- 現在では多くの精度の高い画像認識のモデルが使用されている

---

## 物体認識①

- ILSVRC
物体認識タスクの精度を競う大会、ImageNetを使用する
- ImageNet

---

## 数千万枚以上の画像ある大規模データベースのこと

- 画像にはそれぞれラベルが設定されているが、

---

## 中には誤りのあるラベルも存在するので注意が必要である

---

## 物体認識①

- ILSVRC
2012年：AlexNetが優勝
2014年：GoogLeNetが優勝

---

## VGGNetが準優勝

2015年：ResNetが優勝
2017年：SENetが優勝

---

## 物体認識①

- CNNの発展形

---

## 2012年トロント大学のジェフリー‧ヒントンが中心となった

---

## SuperVisionがILSVRCで優勝する（モデルはAlexNet）

- ディープラーニングを活用した画像認識のシステム
- 当時は人間が特徴量を設定していた（機械学習がメイン）

---

## 物体認識①

- AlexNetの構造

---

## 畳み込み層→プーリング層→畳み込み層→プーリング層

- 畳み込み層→畳み込み層→畳み込み層→プーリング層
- 全結合層→全結合層→全結合層
- 画像認識では、畳み込み層とプーリング層を繰り返して

---

## 精度を上げるアプローチが取られるようになる

---

## 物体認識①

- VGGNet

---

## オックスフォード大学のVGG（Visual Geometry Group）が

開発したモデルで、2014年のILSVRCで準優勝した
- AlexNetよりも層をより深くしたモデルである
- 隠れ層が16層のモデルをVGG-16

---

## 隠れ層が19層のモデルをVGG-19という

---

## 物体認識①

- VGGNet
少ない層で学習を行い、学習が終わったら層を追加して

---

## 層を深くしていく手法が採用されていた

- 小さなフィルタ（ 3 × 3 ）を重ねて畳み込み処理を行っている

---

## 大きなフィルタを使用するよりも表現力が上がるとされている

---

## 物体認識①

- VGGNet
例えば、サイズが 7 × 7 の画像を畳み込み処理を行っていく
- 5 × 5 のフィルタを使用すると 3 × 3 の特徴マップができる
- 3 × 3 のフィルタを2枚重ねて畳み込み処理を行うと

---

## 先ほどと同様に 3 × 3 の特徴マップができる

---

## 物体認識①

- VGGNet（ 5 × 5 のフィルタ）

---

## 物体認識①

- VGGNet（ 3 × 3 のフィルタ）

---

## 物体認識①

- VGGNet（ 3 × 3 のフィルタ）

---

## 物体認識①

- VGGNet

---

## 同じサイズの特徴マップを作るとき小さいフィルタを

---

## 重ね合わせて特徴マップを作る方がモデルの表現力が高くなる

- シンプルな方法であるため多くのモデルに使用される

---

## 物体認識①

- GoogLeNet
2014年のILSVRCで優勝したモデル（22層、Google社）
- インセプションモジュールを採用したモデル
- インセプションモジュール

---

## 複数のフィルタサイズで畳み込み処理を並列に行う構造

---

## 物体認識①

- インセプションモジュール（Inceptionモジュール）

---

## 物体認識①

---

## 特徴マップ

---

## 5 × 5 畳み込み

---

## 特徴マップ

---

## 3 × 3の

---

## maxプーリング

---

## 3 × 3 畳み込み1 × 1 畳み込み

- ResNet
Microsoft社が発表したモデルで、2015年のILSVRCで優勝
- スキップコネクションを加えることで

---

## 層が深くなっても学習が上手くいくようになった

- スキップコネクションは、層を飛び越えて奥の層と結合する

---

## ヒトの認識精度よりも高いモデルになった

---

## 物体認識①

- スキップコネクション

---

## 物体認識①

---

## 畳

---

## み

---

## 込

---

## み

---

## 層

---

## 畳

---

## み

---

## 込

---

## み

---

## 層

---

## 畳

---

## み

---

## 込

---

## み

---

## 層

---

## 畳

---

## み

---

## 込

---

## み

---

## 層

---

## 畳

---

## み

---

## 込

---

## み

---

## 層

- ResNet

---

## 層が深くなっても学習が上手くいくようになった

- 前年に優勝したGoogleNetは22層だったが、
ResNetは152層になり、圧倒的に深層になった
- ResNetは様々な⻑さのネットワークが存在するため

---

## アンサンブル学習の状態になっている

---

## 物体認識①

- ResNet
ResNetの派生モデルとして、
スキップコネクションを改良したDenseNet、

---

## カーネル数を増やしたWide ResNetなどが登場してきた

---

## 物体認識①

- SENet（Squeeze-and-Excitation Networks）

---

## 2017年のILSVRCで優勝したモデルである

- 畳み込み層が出力した特徴マップに、どのデータが予測で

---

## 重要なのかを重み付けするAttention機構を導入したモデル

- Attention機構は汎用的なアイデアであり、
VGG、ResNetなど多くのモデルに導入が可能である

---

## 物体認識①

- SENet（Squeeze-and-Excitation Networks）

---

## 物体認識①

---

## 特徴マップ

---

## 重み付け

---

## 特徴マップ

---

## 画像認識分野

---

## （物体認識②）

作成者：辻 大貴
- 物体認識

---

## 物体認識を行う精度の高いモデルは数多く登場した

- 精度が高くなるにつれてネットワークは深くなり、
パラメータも増え、学習などに時間‧コストがかかってしまう
- 様々な制約からパラメータ数や計算量を減らした

---

## モデルが求められることもある

---

## 物体認識②

- MobileNet

---

## スマートフォンなどのモバイル端末でも利用できるように

---

## 計算量やメモリ使用量が削減されたモデルの1つ

- 層が増えることでパラメータの数が増え計算量も増加する

---

## パラメータ数などを削減して計算量を減らしている

- Depthwise Separable Convolutionという手法が使われている

---

## 物体認識②

- Depthwise Separable Convolution
チャンネル方向と空間方向に対して、畳み込み処理を行う手法
- Pointwise Convolution

---

## チャンネル方向に対して畳み込み処理

- Depthwise Convolution

---

## 空間方向（チャンネルごと）に畳み込み処理

---

## 物体認識②

- 畳み込み処理

---

## 物体認識②

---

## 複数チャンネルが

---

## 重なっている

- 畳み込み処理

---

## 物体認識②

---

## 複数チャンネルが

---

## 重なっている

- Pointwise Convolution

---

## 物体認識②

- Depthwise Convolution

---

## 物体認識②

- Neural Architecture Search（NAS）

---

## ネットワーク構造などを自動的に最適化する手法のこと

- カーネル、カーネルのサイズなど専門家が決めていたものを

---

## RNNや深層強化学習などを用いて最適な値を見つけ出す

- 人が最適なネットワーク構造を探し出すのは困難
- モデル構築などを自動化する手法‧考え方であるAutoMLの1つ

---

## 物体認識②

- NASNet
Googleによって発表されたモデルであり、

---

## ResNetのResidual Blockをベースにしたモデルである

- Residual Blockとはスキップコネクションを含むブロック
- MnasNet

---

## モバイル端末などでも使用できるように設計されたNAS

---

## 物体認識②

- Residual Block

---

## 物体認識②

---

## 畳

---

## み

---

## 込

---

## み

---

## 層

---

## 畳

---

## み

---

## 込

---

## み

---

## 層

---

## 畳

---

## み

---

## 込

---

## み

---

## 層

---

## 畳

---

## み

---

## 込

---

## み

---

## 層

---

## 畳

---

## み

---

## 込

---

## み

---

## 層

- EfficientNet
複合係数を使いネットワークの幅‧深さ‧解像度を最適化し、

---

## 少ないパラメータ数で高精度を実現したモデル（Google）

- 今まではネットワークの幅‧深さ‧解像度を
適当に大規模化させていたが、モデルが複雑で、調整が大変
- 効果的に大規模にしていく方法が求められていた

---

## 物体認識②

- EfficientNet

---

## 転移学習に有用なモデルとして活用されている

- 転移学習とは、ある領域で学習させたモデルを、

---

## 別の領域で活用する技術のことである

- 0からモデルを作るよりも、学習済みモデルを

---

## 使用する方がコストが安く済むという特徴がある

---

## 物体認識②

---

## 画像認識分野

---

## （物体検出と一般物体認識）

作成者：辻 大貴
- 物体検出

---

## 画像に写っている物体を検出すること

- 物体が写っている領域を⻑方形（矩形領域）で囲む

---

## 矩形領域をバウンディングボックスともいう

---

## 画像認識分野（物体検出と一般物体認識）

- 物体検出

---

## 画像内の背景と物体を分けることが難しい

- 複数の物体、異なるクラスの物体を見つけることはより困難

---

## 画像認識分野（物体検出と一般物体認識）

- 一般物体認識
制約のない画像認識のことで、画像から物体を検出し

---

## 検出した物体のクラスを予測する

- 複数の物体を検出でき、一般的なクラスを予測する
- 特定物体認識

---

## 特定のクラスの物体を検出する（りんごや缶コーヒーの種類等）

---

## 画像認識分野（物体検出と一般物体認識）

- 一般物体認識の代表的な手法
- HOG特徴量による物体検出
- R-CNN
- Fast R-CNN
- Faster R-CNN
- YOLO
- SSD
- FPN

---

## 画像認識分野（物体検出と一般物体認識）

- HOG特徴量による物体検出

---

## SVMにHOG特徴量を入力してクラスの分類を行う手法

- 初期の物体検知でよく使用されていた手法
- HOG特徴量は、画像認識における特徴量の1つ
- 画像の局所領域における輝度の勾配方向を

---

## ヒストグラム化したもの

---

## 画像認識分野（物体検出と一般物体認識）

- HOG特徴量による物体検出

---

## 輝度とは単位面積当たりの明るさのこと

- 輝度を微分した値が輝度勾配であり、方向も導き出せる

---

## 画像認識分野（物体検出と一般物体認識）

↑↑
↖↖
↖↖
↖↑
↖←
↑←
↖←
↑↖

---

## 画像輝度勾配方向ヒストグラム

- R-CNN
画像から物体を検出し、その後に物体認識を行う手法
- セレクティブ‧サーチと呼ばれる手法を活用し

---

## 画像から物体候補領域を抽出する

- 候補領域の画像を一定の画像サイズに揃える
- CNNに入力して特徴マップを出力、SVMでクラスを分類

---

## 画像認識分野（物体検出と一般物体認識）

- Fast R-CNN

---

## R-CNNをより高速化したモデル

- R-CNNは候補領域の数だけCNNの処理に時間がかかっていた
- R-CNNと異なり画像全体をCNNに入力し、
特徴マップを作成、作成した特徴マップを使用して

---

## クラスを識別することで処理時間を減らし高速化に成功した

---

## 画像認識分野（物体検出と一般物体認識）

- Fast R-CNN

---

## Fast R-CNNにおいてCNNの処理が終わった

---

## 特徴マップから候補領域を上手く固定サイズの

---

## 特徴マップに変換する手法としてROIプーリングが採用

---

## 画像認識分野（物体検出と一般物体認識）

- Faster R-CNN
Fast R-CNNを改良し、より高速化したモデル
- Fast R-CNNでは候補領域を抽出する方法として

---

## セレクティブ‧サーチが使用されていた

- セレクティブ‧サーチをRegion Proposal Networkという

---

## CNNに置き換えたことで高速化に成功した

---

## 画像認識分野（物体検出と一般物体認識）

- Faster R-CNN

---

## セレクティブ‧サーチをRegion Proposal Networkに変更した

---

## ことでEnd-to-End（E2E）の学習が可能なモデルになった

- E2E（end-to-end）

---

## あるタスクに対して入力から出力までを1つのモデルで行うこと

- End-to-Endの学習とはモデルを一気に学習させること

---

## 画像認識分野（物体検出と一般物体認識）

- Faster R-CNN
Fast R-CNNは、入力から物体候補抽出、
物体候補から物体識別を別々に学習させる必要があり、

---

## 一気に学習させることができなかった（E2Eの学習とは言わない）

- セレクティブ‧サーチを置き換えることで

---

## 一気に学習させることができるようになった

---

## 画像認識分野（物体検出と一般物体認識）

- YOLO（You Only Look Once）
画像全体をCNNに1回入力するだけで、

---

## 物体領域の切り出しと物体の認識を同時に行うモデル

- SSD（Single Shot MultiBox Detector）

---

## YOLOのように物体領域の切り出しと物体の認識を同時に行う

---

## 画像認識分野（物体検出と一般物体認識）

- FPN

---

## 特徴ピラミッドを使用したモデルのこと

- 特徴ピラミッドを使用することで物体検出の精度が高くなる

---

## 画像認識分野（物体検出と一般物体認識）

---

## 予測

---

## 予測

---

## 予測

---

## スキップ接続

- FPN
異なるスケールの特徴マップを使用することで、
異なるスケールの物体に対して、適切な解像度の特徴マップを

---

## 利用することができるため物体検出の精度高めることができる

- スキップ接続を導入することで計算コストを低下させている

---

## 特徴マップを再利用することで計算量を減らせているため

---

## 画像認識分野（物体検出と一般物体認識）

---

## セグメンテーション

作成者：辻 大貴
- セグメンテーション

---

## 画像に写っている犬や猫などの物体を画素ごとに分割すること

- 画像内の物体を画素ごとに分割するタスクを
セグメンテーションタスクという、以下は代表的な手法
- セマンティックセグメンテーション
- インスタンスセグメンテーション

---

## セグメンテーション

- セマンティックセグメンテーション

---

## 対象となる画像の全ての画素にクラスのラベル付けを行う

- 同一クラスの場合は個々の物体を区別せずに、

---

## ひとまとまりの物体として識別を行うという特徴がある

- 画像内に車が複数あっても、個々の車として区別されない

---

## まとめて「車」という領域になる

---

## セグメンテーション

- セマンティックセグメンテーション

---

## セグメンテーション

- インスタンスセグメンテーション

---

## 画像に写っている物体に対してクラスラベルを予測する手法

- それぞれの物体に対してIDを与え、同一クラスの物体でも

---

## 別の物体として識別する手法である

- 空などの形が定まっていない物体はクラスラベルを予測しない
- 複数の「車」が写っていたら、個々の物体として識別する

---

## セグメンテーション

- インスタンスセグメンテーション

---

## セグメンテーション

- パノプティックセグメンテーション

---

## セマンティックセグメンテーションと

---

## インスタンスセグメンテーションを組み合わせた手法

- ビルや道路にはセマンティックセグメンテーション

---

## 人などにはインスタンスセグメンテーション を行う

- 画像に写っている物体に対して全てクラスラベルを予測する

---

## セグメンテーション

- 代表的な手法
- セマンティックセグメンテーション
FCN、Segnet、U-net、PSPNet など
- インスタンスセグメンテーション
Mask R-CNN、YOLACT、YOLACT＋＋ など

---

## セグメンテーション

- FCN（完全畳み込みネットワーク）

---

## 一般的にCNNで使われている全結合層を

---

## 畳み込み層に置き換えたネットワークを持つモデル

- 畳み込み層により特徴マップは小さくなるが、

---

## 画素ごとにラベルを設定するため

---

## 入力画像サイズまで拡大する処理を行う必要がある

- 画像サイズを拡大させる手法をアンサンプリングという

---

## セグメンテーション

- SegNet（セグネット）

---

## FCNと同様に全結合層を畳み込み層に置き換えたモデル

- 特徴を抽出していくエンコーダと特徴マップを入力サイズに

---

## 戻していくデコーダが対象的に配置されている

---

## セグメンテーション

---

## 入

---

## 力

---

## 出

---

## 力

---

## エンコーダデコーダ

- U-Net

---

## SegNetと同様にエンコーダとデコーダの構造を持つモデル

- デコーダで特徴マップを拡大するとき

---

## 対応するエンコーダで作成される特徴マップを利用する

---

## セグメンテーション

- U-Net

---

## セグメンテーション

---

## 入力

---

## 出力

---

## 畳み込み

---

## アンサンプリング

---

## プーリング

- PSPNet

---

## エンコーダとデコーダの間にPyramid Pooling Moduleという

---

## モジュールを追加したモデルのこと

- Pyramid Pooling Module

---

## 特徴マップを複数の解像度でプーリングを行うことで

---

## 複数解像度の特徴マップを作成することでできる

---

## セグメンテーション

- PSPNet
- Pyramid Pooling Module
さまざまなスケールの特徴を抽出することで、
大域的な情報、局所的な情報を獲得できる
- 物体に応じた特徴マップを使用することで

---

## 物体の識別精度などを高めることができる

---

## セグメンテーション

- PSPNet

---

## セグメンテーション

---

## 入

---

## 力

---

## 出

---

## 力

---

## エンコーダデコーダ

---

## 特徴マップ特徴マップ

---

## Pyramid Pooling Module

- セマンティックセグメンテーションの問題点
幅広い情報を集約することが大切になるが、

---

## 幅広い情報を集約するためにはカーネルサイズが大きくなる

- カーネルサイズが大きくなると重みが増えるため

---

## 計算量が増えてしまうという問題点がある

---

## セグメンテーション

- セマンティックセグメンテーションの問題点

---

## セグメンテーション

---

## 3 × 3フィルタ7 × 7フィルタ

---

## 重みは5倍以上

- セマンティックセグメンテーションの問題点

---

## Atrous convolution（Dilated convolution）という

畳み込み処理を行うことで、計算量‧パラメータが

---

## 少なくても広い範囲の情報を集約できるようになった

- Atrous convolution（Dilated convolution）

---

## ピクセルの間隔をあけて畳み込み処理を行う手法のこと

---

## セグメンテーション

---

## 特徴マップ

- Atrous convolution（Dilated convolution）

---

## セグメンテーション

---

## 3 × 3フィルタ画像

- DeepLab
Atrous convolution ( Dilated convolution ) を導入したモデル
- DeepLab V3+
DeepLabを改良し、ASPPを採用したモデルのこと
- ASPP（Atrous Spatial Pyramid Pooling）とは

---

## 空間ピラミッドプーリング（SPP）を拡張させたものである

---

## セグメンテーション

- SPP（Spatial Pyramid Pooling）

---

## 複数のスケールでプーリングを行う手法

---

## セグメンテーション

---

## 3 × 3フィルタ

- SPP（Spatial Pyramid Pooling）

---

## 複数のスケールでプーリングを行う手法

---

## セグメンテーション

---

## 5 × 5フィルタ

---

## 3 × 3フィルタ

- ASPP（Atrous Spatial Pyramid Pooling）

---

## 複数のスケールでプーリングを行う手法

- ピクセルの間隔が異なる特徴

---

## セグメンテーション

- ASPP（Atrous Spatial Pyramid Pooling）

---

## 複数のスケールでプーリングを行う手法

- ピクセルの間隔が異なる特徴

---

## セグメンテーション

- ASPP（Atrous Spatial Pyramid Pooling）

---

## 複数のスケールでプーリングを行う手法

- ピクセルの間隔が異なる特徴

---

## セグメンテーション

- Mask R-CNN

---

## 物体検出とインスタンスセグメンテーションを同時に行う手法

- 物体検出はFaster R-CNNを活用し、

---

## インスタンスセグメンテーションはFCNを活用している

- 1つのモデルが複数のタスクをこなす手法をマルチタスク

---

## Mask R-CNNはマルチタスクの1種である

---

## セグメンテーション

- YOLACT
YOLOの派生型のモデルで、物体検出と

---

## インスタンスセグメンテーションを行うことができるモデル

- YOLACT++

---

## YOLACTを改善した手法のこと

---

## セグメンテーション

---

## 姿勢推定

作成者：辻 大貴
- 姿勢推定

---

## 人間の頭や足などの関節位置を推定すること

- Convolutional Pose MachinesやOpen Poseが代表的なモデル
- Convolutional Pose Machines（CPM）
一連のCNNを組み合わせることで、
画像から信頼度マップを生成し、関節などの位置を推定する

---

## 姿勢推定

- Convolutional Pose Machines（CPM）
信頼度マップとは、関節などと推定された場所に

---

## マッピングされたもの（ヒートマップと呼ばることもある）

---

## 姿勢推定

- Open Pose
関節の位置が分かっても、複数の人が存在する場合、

---

## どの関節同士を繋げればいいか分からない

- Parts Affinity Fieldsという手法を
導入することで、複数の人間の関節位置を

---

## 推定できるようになったモデル

---

## 姿勢推定

---

## トランスフォーマーと

---

## 画像処理

作成者：辻 大貴
- ViT（Vision Transformer）

---

## 2020年にGoogleが発表した画像認識モデル

トランスフォーマーを使用したモデルで、従来のCNNを使った
モデルよりも性能が高く、計算コストを削減することができる
- 画像を複数に分割、分割した画像（パッチ）間の関係性を
考慮（重み付け）して、クラスを分類（広範囲の情報を考慮）

---

## トランスフォーマーと画像処理

- ViT（Vision Transformer）

---

## トランスフォーマーと画像処理

- ViT（Vision Transformer）

---

## トランスフォーマーと画像処理

---

## クラスの出力

---

## 各パッチの関連度を計算

- Swin Transformer

---

## 2021年に発表されたトランスフォーマーを使用したモデル

- ViT（Vision Transformer）の問題点を改良したモデル
- 問題点

---

## パッチを小さくすると一気に計算コストが高くなる

パッチの大きさが一定で、画像全体と細部の特徴の把握が困難

---

## トランスフォーマーと画像処理

- Swin Transformer

---

## 複数のパッチのグループ( Window )内でパッチ間の関連度を計算

---

## トランスフォーマーと画像処理

- Swin Transformer
Windowをずらして、パッチ間の関連度を計算
- Windowに分割したことで、本来は繋がりの深いパッチ間の

---

## 関連度を考慮することができないという課題を解決

---

## トランスフォーマーと画像処理

- Swin Transformer

---

## トランスフォーマーと画像処理

- Swin Transformer
パッチの大きさを変更して、パッチ間の関連度を計算

---

## トランスフォーマーと画像処理

---

## 音声処理

作成者：辻 大貴
- 音声認識

---

## 人間の発した声をコンピュータに認識させる技術のこと

- 人間が発した声はアナログなデータなので、

---

## コンピュータが分かるようにデジタルデータに変換する必要

- アナログデータからデジタルデータに変換することを

---

## アナログデジタル変換（A-D変換）という

---

## 音声処理

- 音声認識

---

## アナログデジタル変換（A-D変換）でよく使用される手法に

---

## パルス符号変調（PCM）がある

- アナログデータからデジタルデータに変換していくステップ
１.標本化：連続したアナログ信号を一定時間ごとに測定する
２.量子化：信号の大きさを離散的な値で近似的に表す
３.符号化：処理しやすいデジタルデータ（ビット列）に変換

---

## 音声処理

- サンプリング周波数

---

## 単位時間あたりに行った標本化処理の回数のこと

- サンプリング周波数の2分の1の周波数をナイキスト周波数
- アナログ信号をデジタル信号に変換するとき、
元の信号の最大周波数の2倍より高い周波数で標本化すれば、

---

## 元の信号の波形を再現できるという法則をサンプリング定理

---

## 音声処理

- 音声認識

---

## 音声認識で必要な特徴量（音色など）を取り出すために

---

## デジタルデータ化した音声データを周波数スペクトルに変換

- 高速フーリエ変換（FFT）という手法を使用する
- スペクトル：音などの波を構成する成分に分解し、

---

## 各成分（周波数）の強度を分布したもの

---

## 音声処理

- スペクトル

---

## 音声処理

---

## 分解

- 音声認識

---

## 音声認識において音色は特徴量として使用される

- 同じ高さの音でも音色によって違う音と感じる（楽器）

---

## 同じ周波数でも波の形が異なることから音色の違いが生まれる

---

## 音声処理

- 音声認識

---

## スペクトル包絡は音色の違いを表す

- 音声の違いを表すスペクトル上の大まかな形を表した線のこと

---

## 音声処理

---

## 周波数

---

## 振幅

- 音声認識

---

## スペクトル包絡を求めるときによく用いられる手法に

---

## メル周波数ケプストラム係数（MFCC）がある

- MFCCに値を入力するとスペクトル包絡に相当する値が出力

---

## 出力された値を特徴量として使用していく

- この値を出力するために様々な処理を行ってきた

---

## 音声処理

- 音声認識

---

## 周波数スペクトルに現れる周波数のピークのことを

フォルマントといい、その周波数をフォルマント周波数という

---

## 音声処理

---

## 周波数

---

## 振幅

---

## フォルマント

- 音声認識

---

## 音韻が同じならばフォルマント周波数は近くなる

- 音韻

---

## 母語話者が同じ1つの音と認識できる音の体系‧総称のこと

- 母語話者が同じ音として認識するグループのこと

---

## 音声処理

- 音韻

---

## 日本人は「lock」「rock」を同じ「ロック」として認識

- 「l」と「r」の区別をしないため、同じ音として認識
- 「æ」「ɑː」「ʌ」を区別する言語ではないので、

---

## 同じ「ア」として認識する

- 言語によっては異なる音として認識する場合もある

---

## 音声処理

- 音声認識
前処理が終わったら、音響モデルを使用して音声認識を行う
- 音響モデルとは、音声から音素を抽出するモデルのこと
- 音素

---

## 母語話者が同じ音として認識するグループのこと

- 音韻と同じ意味で使用されるが、音韻の方が音素より広い概念

---

## 音声処理

- 音素と音韻
音韻は音素に音の⻑短、アクセントなどを含めたものであり、

---

## 歴史的な文脈で使用されることが多い

- 試験対策として音韻が同じならばフォルマント周波数は近くなる

---

## 音声認識を行うために音声から音素を抽出する必要がある

---

## というキーワードを押さえておく

---

## 音声処理

- 音声認識

---

## 音響モデルの1つに隠れマルコフモデル（HMM）がある

- 音素列と単語を対応させた辞書を使用して学習を行う

---

## HMMは音声認識でよく使われていたモデルであった

- 現在はディープラーニング技術を使用したモデルが使用

---

## DNN-HMMやWaveNetなど有名な手法である

---

## 音声処理

- DNN-HMM

---

## Microsoftが発表したモデルでディープラーニング技術と

---

## 隠れマルコフモデル（HMM）を組み合わせたモデル

- WaveNet

---

## DeepMindが開発した音声認識‧音声合成を行うモデル

- ディープラーニング（CNN）を活用したモデル

---

## 音声処理

- WaveNet
人間に近い自然な音声を生成することができ、

---

## スマホやスマートスピーカーで活用されている

- 実時間の20分の1で音声を生成することができる
- Dilated Causal Convolutionという仕組みが導入されている

---

## 少ないパラメータで広範囲の畳み込みが可能

---

## 音声処理

- Dilated Causal Convolution

---

## 音声処理

---

## 出力

---

## 隠れ層

---

## 隠れ層

---

## 入力

- Dilated Causal Convolution

---

## 音声処理

---

## 出力

---

## 隠れ層

---

## 隠れ層

---

## 入力

- Dilated Causal Convolution

---

## 音声処理

---

## 出力

---

## 隠れ層

---

## 隠れ層

---

## 入力

- Dilated Causal Convolution

---

## 音声処理

---

## 出力

---

## 隠れ層

---

## 隠れ層

---

## 入力

- Dilated Causal Convolution

---

## 音声処理

---

## 出力

---

## 隠れ層

---

## 隠れ層

---

## 入力

- Dilated Causal Convolution

---

## 音声処理

---

## 出力

---

## 隠れ層

---

## 隠れ層

---

## 入力

- Dilated Causal Convolution

---

## 音声処理

---

## 出力

---

## 隠れ層

---

## 隠れ層

---

## 入力

- Dilated Causal Convolution

---

## 音声処理

---

## 出力

---

## 隠れ層

---

## 隠れ層

---

## 入力

- Dilated Causal Convolution

---

## 音声処理

---

## 出力

---

## 隠れ層

---

## 隠れ層

---

## 入力

- 音声合成（音声生成）

---

## 人間らしい音声を生成すること

- 文章から音声を生成することをText-to-Speech（TTS）という
- 混合正規分布モデル（GMM）や隠れマルコフモデル（HMM）が

---

## 代表的な合成音声のモデルであった

- 現在はディープラーニング技術を使用したモデルが使用

---

## 音声処理

---

## 音声認識と合成音声

作成者：辻 大貴
- 音声認識

---

## 音声からテキストに出力する手法で

---

## STT（Speech-to-Text）と呼ばれている

- テキストから音声を出力する手法を

---

## TTS（Text-to-Speech）という

- テキストから音声を生成する合成音声はTTSの１つ

---

## 音声認識と合成音声

---

## 音声

---

## テキスト

- 音声認識

---

## 入力された音声データ（単語）と学習した音声データ（単語）の

---

## 類似度をもとにテキストデータとして出力されている

---

## 音声認識と合成音声

---

## 類似度

- 音声認識

---

## 人によって同じ単語を発していても異なる波⻑になる

- 学習した音声データ（単語）と基本的には完全に一致しない
- データ間の最適な対応関係を見つけるために、
音声データ（単語）を変形させ、類似度を計算していく
- このような手法のことを伸縮マッチングという

---

## 音声認識と合成音声

- 音声認識

---

## 伸縮マッチングの手法の１つとして

---

## 動的計画法（DP）を使用したDPマッチングが存在する

- 動的計画法（DP）とは、計算量が多い問題を
計算量が少ない問題に分割し、計算量が少ない問題の
計算結果などを再利用することで、効率的に問題を解く手法

---

## 音声認識と合成音声

- 動的計画法（DP）

---

## 音声認識と合成音声

---

## 問題

---

## 問題A

---

## 問題B

---

## 問題C

---

## 計算方法X

---

## 計算方法Y

---

## 計算方法X

---

## 計算結果を

---

## 活用

- 音声認識
RNNなどでは、入力された音声データの数（入力数）と

---

## 出力すべき音声データの数（出力数）が一致するように

---

## CTCという技術が使用されている

- モデルによってCTC‧DPマッチングなどを使用するかが変わる
DPマッチングは画像認識、異常検知などでも使用される

---

## 音声認識と合成音声

- 音声認識
議事録などでは、話者を識別して、テキスト化したい場合もある
- 音声から感情を分析して、相手の感情に合わせて
合成音声で音声を出力したい場合は、感情分析も必要になる

---

## 音声認識と合成音声

- 合成音声

---

## 合成音声には波形接続TTSやパラメトリックTTSという方法がある

- 波形接続TTS
１人の話者の発した単語などを記録し、

---

## 記録した単語などを組み合わせて音声を生成する方法

---

## 音声認識と合成音声

- 合成音声
- パラメトリックTTS
抑揚、声の高さ、感情などを入力して音声を生成する方法
- 数値を変更することで、出力される音声が変化する
- 波形接続TTSでは難しかったことが可能になった

---

## ディープラーニング技術の発展によるものが大きい

---

## 音声認識と合成音声

- メル尺度

---

## 人間が感じる音の高さに基づき作成された尺度

- 人間は高音になればなるほど音の高さの変化を感じにくい
- メル尺度の数値が1増えるごとに、

---

## 音の高さが同じだけ高く感じられる

---

## 音声認識と合成音声

---

## Hz

---

## 音の感じ方

- メル尺度

---

## 高音の分解能より低音の分解能の方が高いため

---

## 高音になればなるほど音の高さの変化を感じにくい

- 分解能

---

## どれだけ細かく測定できるかを表す能力のこと

- 機械などに対しても使用される

---

## 音声認識と合成音声

---

## 自然言語処理の流れ

作成者：辻 大貴
- 自然言語処理（NLP）

---

## 人間が使っている言語をコンピュータに処理させること

- 自然言語は画像や音声と異なり数値化することが困難
画像はピクセルで数値化、音声は振幅などで数値化が可能
- 自然言語処理はただ単語として処理するのではなく、

---

## 単語の意味や文脈なども考慮する必要（単語の数値化が困難）

---

## 自然言語処理の流れ

- 自然言語処理

---

## 自然言語処理は一般的に以下のような工程で処理が行われる

---

## １.形態素解析

---

## ２.構文解析

---

## ３.意味解析

---

## ４.文脈解析

---

## 自然言語処理の流れ

---

## １.形態素解析

文章を意味を持つ最小の単位に切り分け、品詞を推定していく
- 意味を持つ最小の単位のことを形態素という
- 今日は良い天気です

---

## 今日  |   は   |   良い   | 天気 |   です

---

## 名詞 助詞 形容詞 名詞 助動詞

---

## 自然言語処理の流れ

---

## １.形態素解析

---

## 日本語は英語と異なり切り分ける処理が難しい特徴がある

- 英語は単語ごとにスペースが空いているため単語を判断しやすい
This is a pen. ならThis、is、a、penに分けることができる
- 日本語は単語ごとにスペースがないため単語が判断しにくい

---

## 日本語の文章を形態素に分けるプログラムが開発されている

---

## 自然言語処理の流れ

---

## ２.構文解析

---

## 形態素間の関係性を解析すること

- 文の句構造を解析する句構造解析、
主語や述語、修飾語や被修飾語のように

---

## 単語同士の関係性を解析する係り受け解析などがある

- 分析結果は構文木などを使用して表示される

---

## 自然言語処理の流れ

- 句構造解析

---

## 自然言語処理の流れ

---

## 文

---

## 後置詞句動詞句

---

## 名詞

---

## 私は傘をたたむ

---

## 後置詞句動詞句

---

## 助詞名詞助詞動詞

- 係り受け解析

---

## 自然言語処理の流れ

---

## 私は傘を

---

## たたむ

---

## ３.意味解析

---

## 文の意味を正しく解釈するために行う解析のこと

- 単語間の関係性も判断していく
- 私は雨が降ってきたので、右手に持っていた傘をさした

---

## 「雨と傘」「雨と降る」は関係性が高いが

---

## 「右手と傘」「雨と右手」は関係性が低い

---

## 自然言語処理の流れ

---

## ４.文脈解析

文を超えて、文章全体の意味を解析を行うこと
- 代名詞や省略された名詞などを推定する照応解析

---

## 関連した一連の文の意味的な関係性を推定する談話解析

- 私は傘を持っている。雨が降ってきたので、それをさした。
それとは何か、誰が傘をさしたのか など推定していく

---

## 自然言語処理の流れ

---

## 自然言語処理の前処理

作成者：辻 大貴
- 単語の数値化

---

## コンピュータは単語の意味が分からない

- 単語を数値化して意味を計算して求める必要がある
- 意味解析や文脈解析などでも数値を使用して

---

## 意味や文脈を推定している

- テキストデータを前処理でベクトルや行列に変換している

---

## 自然言語処理のための前処理

- 単語の数値化
ベクトル：値や文字を1列または1行に並べたもの
行列  ：値や文字を縦横に並べたもの

---

## 自然言語処理のための前処理

---

## ベクトル行列

- 前処理
- データクレンジング
- 単語の分割（形態素解析など）
- 単語のベクトル化

---

## 自然言語処理のための前処理

- データクレンジング
データの品質を向上させるために、
不正確、欠損、重複などのデータを修正、削除していくこと
- 言葉の間違いの修正、不要な文字列の削除 など
- 傘ををたたむ → 「を」が1つ多いので「を」を削除

---

## <div class=”red”>傘</div> → HTMLのタグを削除

---

## 自然言語処理のための前処理

- 単語の分割

---

## 文字列をn個の単語で分割していく（単語N-gram）

文章を1単語で分割する場合：単語ユニグラム
文章を2単語で分割する場合：単語バイグラム
文章を3単語で分割する場合：単語トライグラム

---

## 自然言語処理のための前処理

- 単語N-gram

---

## 文章が「今日は良い天気」の場合

- 単語ユニグラム：今日 | は | 良い | 天気
- 単語バイグラム：今日 は | は 良い | 良い 天気
- 単語トライグラム：今日 は 良い | は 良い 天気

---

## 自然言語処理のための前処理

- 単語の分割（参考）

---

## 任意の文章や文字列をn文字で分割することを文字N-gramという

文章を1文字で分割する場合：文字ユニグラム
文章を2文字で分割する場合：文字バイグラム
文章を3文字で分割する場合：文字トライグラム

---

## 自然言語処理のための前処理

- 単語のベクトル化
単語をベクトルに変換していくが、変換方法には様々な種類
- ベクトルの表現方法の様々なものがある
- ワンホットベクトルのように

---

## 1つの概念を1つの成分で表すような表現方法（局所表現）

- 単語を低次元のベクトルで表現方法（分散表現）

---

## 自然言語処理のための前処理

- ワンホットベクトル
1つの値が1、他の値が0になっているベクトルのこと
- 「今日 | は | 良い | 天気」 ならば以下の通りになる
- 今日 => [1, 0, 0, 0]
- は  => [0, 1, 0, 0]
- 良い => [0, 0, 1, 0]
- 天気 => [0, 0, 0, 1]

---

## 自然言語処理のための前処理

- 単語のベクトル化

---

## Bow（Bag-of-Words）を使用して単語をベクトルに変換

---

## 1.文章を単語に分割していく

---

## 2.分割した単語にIDをつける

---

## 3.全ての単語をワンホットベクトルに変換

---

## 4.各ワンホットベクトルを足し合わせる

---

## 自然言語処理のための前処理

- Bow

---

## 1.文章を単語に分割していく

- 「今日は良い天気良い気分」を単語に分割していく

---

## 「今日」「は」「良い」「天気」 「良い」「気分」

---

## というように文章を単語に分割していく

---

## 自然言語処理のための前処理

- Bow

---

## 2.分割した単語にIDをつける

- 「今日」は1、「は」は2、「良い」は3、
「天気」は4、 「良い」は3、「気分」は5のようIDを設定する
- 同じ単語には同じIDを割り当てていく

---

## 自然言語処理のための前処理

- Bow

---

## 3.全ての単語をワンホットベクトルに変換

- 「今日」が1、「は」が2、「良い」が3、
「天気」が4、 「良い」が3、「気分」が5なので、
- 「今日」=>[1, 0, 0, 0, 0]、「は」=>[0, 1, 0, 0, 0]、
「良い」=>[0, 0, 1, 0, 0]、「天気」=>[0, 0, 0, 1, 0]、
「良い」=>[0, 0, 1, 0, 0]、「気分」=>[0, 0, 0, 0, 1]、

---

## 自然言語処理のための前処理

- Bow

---

## 4.各ワンホットベクトルを足し合わせる

「今日」=>[1, 0, 0, 0, 0]、「は」=>[0, 1, 0, 0, 0]、
「良い」=>[0, 0, 1, 0, 0]、「天気」=>[0, 0, 0, 1, 0]、
「良い」=>[0, 0, 1, 0, 0]、「気分」=>[0, 0, 0, 0, 1]から
- 「今日は良い天気良い気分」は[1, 1, 2, 1, 1]に変換される

---

## 文章中の単語の出現回数をカウントしたものといえる

---

## 自然言語処理のための前処理

---

## 今日は良い天気気分

11211
- Bow

---

## 「今日は良い天気良い気分」をベクトルに変換する方法

- 単語の出現回数をカウントしたものを表にまとめて

---

## ベクトルに変換していくことも可能 [1, 1, 2, 1, 1]

---

## 自然言語処理のための前処理

- Bow

---

## 単語の順番を考慮しないため

---

## 異なる意味のテキストでも同じベクトルになる

- 「私は猫を噛む」、「猫は私を噛む」はどちらも同じ

---

## ベクトルになってしまうという特徴がある

---

## 自然言語処理のための前処理

- Bow
- ベクトルに直すをどちらも[1, 1, 1, 1, 1]になってしまう

---

## 自然言語処理のための前処理

---

## 私は猫を噛む

---

## 私は猫を噛む11111

---

## 猫は私を噛む11111

- Bow

---

## 局所的な情報を程度保持することが考えられる

- その中の1つにBag-of-n-gramsがある

---

## BoWと単語n-gramを組み合わせたもの

- 文章を2単語や3単語など複数の単語で分割することで、

---

## 局所的な情報を保持することができる

---

## 自然言語処理のための前処理

- Bag-of-n-grams（2単語）

---

## 「私は猫を噛む」=>「私は」「は猫」「猫を」「を噛む」

---

## 「猫は私を噛む」=>「猫は」「は私」「私を」「を噛む」

---

## 自然言語処理のための前処理

---

## 私はは猫猫をを噛む猫はは猫私を

---

## 私は猫を噛む1111000

---

## 猫は私を噛む0001111

- テキスト間の関係性

---

## テキストに出てくる単語をベクトルの形で表すことで

---

## テキスト間の類似度をコサイン類似度を使用して

---

## 計算することができる（-1〜1の値をとる）

- コサイン類似度

---

## テキスト間の関係性などを求めるときに使用される指標

---

## 自然言語処理のための前処理

- テキスト間の関係性
テキストの類似度を計算するとき、

---

## 専門用語など一般的でない単語がお互いのテキストに

出現しているとき、テキストの類似度は高いと判断できる
- テキスト内の単語の珍しさや単語の出現頻度を考慮した方が

---

## テキストの類似度をより正確に求めることができる

---

## 自然言語処理のための前処理

- テキスト間の関係性

---

## 単語の重要度を計算する手法としてTF-IDFがある

- 単語の出現頻度を表すTF（Term Frequency）、

---

## 文章に含まれている単語がどれだけ珍しいかを表す

---

## IDF（Inverse Document Frequency）から

---

## 単語ごとの重要度を計算していく

---

## 自然言語処理のための前処理

---

## 局所表現と分散表現

作成者：辻 大貴
- 局所表現

---

## ワンホットベクトルのように

---

## 1つの概念を1つの成分で表すような表現方法のこと

- 全ての単語を独立したものとして扱うため

---

## 単語間の概念の近さを考慮することができない

- 高次元になるため計算量が膨大になる（0の成分が多くなる）

---

## 局所表現と分散表現

- 分散表現

---

## 局所表現の問題を解決したのが分散表現（単語埋め込み）

- 単語を低次元のベクトル（複数の成分）で表現することで、

---

## 単語間の関係などを計算することが可能になった

- 王 = (4.55, 1.20, 3.28, 0.71) などのように複数の成分で表現

---

## 概念的に近い単語ほど類似度が高くなる特徴がある

---

## 局所表現と分散表現

- 分散表現

---

## 局所表現と分散表現

---

## 王

---

## 女王

---

## 彼

---

## 彼女

---

## ⻑い短い

- 分散表現
単語の分散表現を獲得する手法としては、大きく分けて

---

## カウントベースの手法と推論ベースの手法がある

- カウントベースの手法
周囲の単語の頻度によって単語を表現する方法で、

---

## コーパス全体の統計データから単語の分散表現を獲得する

---

## 局所表現と分散表現

- 分散表現
- 推論ベースの手法

---

## ニューラルネットワークを用いて分散表現を獲得する

- カウントベースの手法の場合は大規模なデータを

---

## 一度にまとめて処理する必要があったため

---

## 学習時間が非常に⻑く現実的でなかった

---

## 局所表現と分散表現

- 分散表現
- 推論ベースの手法
学習データを逐次的に学習できる上に、

---

## 容易に並列計算ができるため学習時間を短縮することが可能

- 代表的な推論ベースの手法にWord2Vecがある

---

## 局所表現と分散表現

- word2vec
「同じ文脈において現れる単語は、似た意味を持つ」という

---

## 分布仮説とニューラルネットワークを用いた手法

- トマス‧ミコロフが提案したモデル
- 王様 ー 男性 + 女性 = 女王 というように表すことができる

---

## ベクトルを使うことで様々な概念を説明できる

---

## 局所表現と分散表現

- 分散表現

---

## 王様    ー  男性  +  女性  =   女王

---

## 局所表現と分散表現

- 分散表現

---

## word2vecは以下の2つのモデルが使用されている

- CBOW（Continuous Bag-of-Words）

---

## 周囲の単語からある単語を推測するモデル

- スキップグラム
ある単語を与えて、その周囲の単語を推測するモデル

---

## 局所表現と分散表現

- CBOW（Continuous Bag-of-Words）
- スキップグラム

---

## 局所表現と分散表現

---

## 単語？単語単語単語

---

## ？？単語単語単語

- fastText

---

## word2vecを開発したトマス‧ミコロフが開発したモデル

---

## 学習内容に部分文字列（文字列の一部）も含めることで

---

## 訓練データに存在しない未知語（OOV）にも強いモデル

- word2vecよりも学習に要する時間が短く、

---

## 単語の活用などを考慮することができるようになった

- 「walk」「walks」「walked」「walking」などの活用を考慮

---

## 局所表現と分散表現

- ELMo
word2vecを改良したモデルで、双方向RNNを活用した手法
- 複数の意味を持つ単語でも前後文から適切な意味を推測可能
- word2vecやfastTextは文脈などによって変わる

---

## 単語を上手く扱うのが苦手だった

- ELMoは文脈を考慮して単語の分散表現を計算することが可能

---

## 局所表現と分散表現

- Doc2Vec

---

## word2vecの派生モデルである

- 文章間の類似度を計算することができるモデルである

---

## 局所表現と分散表現

---

## 自然言語処理

作成者：辻 大貴
- 自然言語処理の代表的なモデル
自然言語処理においてGPT、BERTが代表的なモデルである
- GPTやBERTは、事前に大量のデータを学習している
事前学習モデルで、後から少量の学習データを使用して

---

## 用途に合わせたモデルを作成できる

- GPTやBERT以外にも多くの事前学習モデルが登場している

---

## 自然言語処理

- 自然言語処理の代表的なモデル
転移学習などで用いるモデルを作るために、

---

## 事前に大量のデータを使用して学習することを事前学習という

- 転移学習とは、ある領域で学習させたモデルを、
別の領域で活用する技術のことで、コスト削減に繋がる

---

## 自然言語処理

- GPT

---

## OpenAIが開発した自然言語処理モデル

- 大規模なコーパスを使用して事前学習を行い、

---

## ファインチューニングすることで様々な場面で活用

- トランスフォーマの「デコーダ」と似た構造を持っている

---

## 初代のGPTはパラメータ数は1億程度だった

---

## 自然言語処理

- GPT

---

## 2019年に公開された「GPT-2」のパラメータ数は約15億個

---

## 2020年に公開された「GPT-3」のパラメータ数は約1,750億個

---

## 2023年に公開された「GPT-4」のパラメータ数は約100兆個

- 2022年に公開されたAIチャットサービス「ChatGPT」は

---

## 2ヶ月でユーザー数が1億人を超えた

---

## 自然言語処理

- GPT
GPT-3やGPT-4を使用することで、人間が作ったような

---

## 質の高い文章‧コードなどを作成できる

- 文章の冒頭を与えると続きの文章を作成してくれる
与えた文章を学習して、目的に応じた文章を返している
- 少量のデータで学習できる手法をFew Shot Learningという

---

## 自然言語処理

- BERT

---

## 2018年にGoogle社が発表した自然言語処理モデル

- パラメータ数は3億程度である
BERTは従来のモデルで使用されていたRNNの代わりに、

---

## トランスフォーマーと呼ばれるモデルを採用している

- エンコーダにトランスフォーマーを使用している
- MLMとNSPという2つのタスクを実行して事前学習を行っている

---

## 自然言語処理

- MLM（Masked Language Model：マスク言語モデル）
文章の一部を隠して見えない状態で入力し、

---

## 前後文から隠した文章を予測するタスクのこと

- NSP（Next Sentence Prediction）
2つの文章を入力し、連続した文章か推測するタスクのこと

---

## 自然言語処理

- 軽量版モデル

---

## BERTをベースに精度を維持しながらパラメータ数を減らした

ALBERT、DistilBERTなどが2019年に公開された
- Microsoftは自社で開発していたモデルとBERTを

---

## 組み合わせた「MT-DNN」を発表しBERTを上回った

---

## 自然言語処理

- 高精度なモデル
- Megatron-LM
NVIDIAが発表したモデルで、パラメータ数は約80億
- Turing-NLG
Microsoftが発表したモデルで、パラメータ数は約170億
- これら以外にも様々なモデルが登場し、日々精度が向上している

---

## 自然言語処理

---

## 対話型AI

作成者：辻 大貴
- 対話型AI

---

## 自然な会話を行うことができる人工知能のこと

- ChatGPT、Siriなどが挙げられる
- ChatGPTは大規模言語モデルであるGPTをベースに作成された

---

## チャット形式の対話型サービスである

- OpenAIが開発し、提供しているサービスである

---

## 対話型AI

- 対話型AI

---

## 以前Googleが提供していたチャット形式の対話型サービスに

---

## 「Bard」がある（2023年3月に提供を開始）

- 大規模言語モデルであるLaMDAをベース作成された
BERT：文脈理解、汎用性を強みにする大規模言語モデル
LaMDA：人間との自然な対話を重視した大規模言語モデル

---

## 対話型AI

- Bardの大規模言語モデルのベース
2023年4月：PaLMに変更
- LaMDAの後続モデルである

---

## LaMDAより汎用性の高いモデルを目指し開発

2023年5月：PaLM2に変更

---

## 対話型AI

- Bardの大規模言語モデルのベース
2024年2月：Geminiシリーズ（Gemini 1.0 Pro）に変更

---

## サービスの名称がBardからGeminiに変更

- GeminiシリーズはPaLM2の後続モデルである
テキスト、画像、音声など様々な種類のデータから

---

## テキストなどを生成することが可能に（マルチモーダル処理）

---

## 対話型AI

- GPT‧BERTとword2vec‧ELMoの違い
GPT‧BERT、word2vec‧ELMoはともに

---

## 大量のデータを使用して学習を行ったモデルである

- GPT‧BERTの場合、応用タスクに合わせて学習済みモデルを

---

## 少量のデータで学習（ファインチューニング）させることで

---

## 応用的なタスクを解くことが可能である

---

## 対話型AI

- GPT‧BERTとword2vec‧ELMoの違い
word2vec‧ELMoの場合、応用タスクを解くためには、

---

## 追加で別のモデルを用意する必要がある

- GPT‧BERTよりも手間がかかるというデメリットがある
- 事前学習と転移学習が可能なGPT‧BERTが大きな影響を与えた

---

## 対話型AI

- 人間のフィードバックによる強化学習（RLHF）
AIの出力に対して、人間が評価（フィードバック）を行い、

---

## 人間が好むような出力ができるように学習させる技術のこと

- 強化学習が使用されており、精度向上に貢献している
- Geminiなどでは、複数のテキストを生成し、

---

## どちらのテキストの方が良いか選択してもらい評価を集めている

---

## 対話型AI

- プロンプト
AIに何かを実行させたり、生成させたりするための指示文のこと
- プロンプトによって生成物の完成度は変わってしまう
- AIに指示を与えるためのプロンプトを作成する

---

## エンジニアをプロンプトエンジニアという

---

## 対話型AI

---

## 自然言語タスク

作成者：辻 大貴
- 自然言語タスク

---

## 自然言語を使用したタスクには様々な種類が存在する

- 人が言葉を通して行っているタスクを全てこなせることが理想
- 代表的な自然言語タスク

---

## 自然言語推論‧評判分析‧文書分類‧意味的類似度判定‧

---

## 質問応答‧固有表現抽出‧品詞タグ付け など

---

## 自然言語タスク

- 自然言語推論
前提と仮説からなる2つの文章を用いて、

---

## 前提と仮説が正しいか矛盾しているかなどを推論するタスク

- 含意関係認識とも呼ばれている
- 前提文から仮説文を導くことができない場合は矛盾

---

## 前提文から仮説文を導くことができる場合は含有と判断する

---

## 自然言語タスク

- 評判分析

---

## 文章から肯定的な意見か否定的な意見かを分類するタスク

- 文書分類

---

## 与えられた文書を1つ以上のカテゴリーに分類するタスク

---

## 自然言語タスク

- 意味的類似度判定

---

## 文章間の意味的な類似度を判定するタスク

- 質問応答
文章と文章に基づいた質問に対して、最適な回答を返すタスク

---

## 自然言語タスク

- 固有表現抽出
文章中から固有表現などを抽出し、あらかじめ定義した

---

## 固有表現分類へ分類するタスク

- 品詞タグ付け

---

## 文章中の単語に対して品詞を付けるタスク

---

## 自然言語タスク

- 言語理解タスク
自然言語処理において、特に文章や背景を理解しないと

---

## 正しく解けないタスクのこと

- 自然言語モデルのベンチマーク（比較するための指標）として、

---

## GLUEやSQuADなどがある

---

## 自然言語タスク

- GLUE

---

## 複数のタスクを使用して評価を行う

- 文章同士の類似度を判定するタスクなどを行い精度をはかる
- SQuAD
短い文章と質問を与え、質問に対する解答を抽出させる
- どれだけ正確に解答を抽出できるかで精度をはかる

---

## 自然言語タスク

- SuperGLUE

---

## GLUEより難易度の高いタスクを含んだベンチマーク

- JGLUE

---

## 日本語の自然言語理解を評価するためのベンチマーク

- GLUEにも様々な種類のベンチマークが存在する

---

## 自然言語タスク

---

## 深層強化学習とゲームAI

作成者：辻 大貴
- 深層強化学習

---

## 強化学習とディープラーニングの手法を組み合わせたもの

- DeepMind社が開発したDQN（Deep Q-Network）が

---

## 基本的な深層強化学習の手法になっている

- ゲームだけでなく、ロボット制御などでも使用されている
- DQNはQ学習とCNNを組み込んだもの

---

## 深層強化学習とゲームAI

- 深層強化学習

---

## Q学習とはQ値を最大にするように学習する手法

- Q値とは行動価値関数から返ってきた値のこと

---

## 深層強化学習では行動価値関数の関数近似をCNNで求めている

- 深層強化学習は、画像を入力して、最適な行動を決定していく
アルゴリズムであり、画像を適切に扱うためにCNNを使用

---

## 深層強化学習とゲームAI

- 深層強化学習
従来の強化学習の場合、ピクセルの値が少し異なるだけでも
実質的には同じ状態にも関わらず、異なる状態と

---

## 判断してしまうため状態の数が莫大になってしまっていた

- 状態が大量にあるとQ値を求めることは非常に難しい
- 行動価値や方策を導き出すことが現実的ではなかった

---

## 深層強化学習とゲームAI

- 深層強化学習

---

## ニューラルネットワークを活用して行動価値や方策を推定する

---

## アプローチが取られるようになった

- CNNに画像を入力し、重要な特徴量を抽出することで

---

## ピクセルの値が少し異なっていても同様の状態と認識可能

- 計算を減らすことができ実務で利用できる計算量になった

---

## 深層強化学習とゲームAI

- 深層強化学習

---

## 深層強化学習では以下の2つの手法が導入された

- 経験再生
- ターゲットネットワーク

---

## 深層強化学習とゲームAI

- 経験再生
エージェントがとった行動などをデータとして蓄積しておき、

---

## 学習時にランダムにデータを抜き出し学習に使う手法

- 訓練データ間の時間的な偏りを少なくすることで

---

## 学習の安定化をはかることができる

- 訓練データに時間的な相関があると学習が安定しない特徴

---

## 深層強化学習とゲームAI

- ターゲットネットワーク
メインとなるQネットワーク以外に、

---

## もう1つのネットワークを使用して学習を行う手法

- Qネットワークとターゲットネットワークは同じ構造を持つ

---

## 深層強化学習とゲームAI

---

## Qネットワーク

---

## (メインのネットワーク)

---

## ターゲットネットワーク

- ターゲットネットワーク

---

## ターゲットネットワークは少し前のQネットワークを使用

- Qネットワークは誤差を求めるごとに更新していくが、

---

## ターゲットネットワークは更新せずに固定させておく

- 定期的にターゲットネットワークの更新を行う

---

## 深層強化学習とゲームAI

- ターゲットネットワーク
NNの学習に、同じNNの出力を使用すると

---

## 学習が安定しにくいという特徴がある

- Qネットワークの出力だけでなく、

---

## ターゲットネットワークの出力も使用することで学習が安定

---

## 深層強化学習とゲームAI

- DQNを発展させた手法
- ノイジーネットワーク
- ダブルDQN（DDQN）
- 優先度付き経験再生
- デュエリングネットワーク
- カテゴリカルDQN
- Rainbow

---

## 深層強化学習とゲームAI

- ノイジーネットワーク
ネットワークに意図的にノイズを加えることで、

---

## 異なる行動を取り広範囲の探索を行えるようにした手法のこと

- DQNは行動価値が高い行動を選択してしまう特徴がある
- 行動価値が高い行動以外の行動を取る確率が低くなり、

---

## 広範囲の探索が困難という特徴があった

---

## 深層強化学習とゲームAI

- ダブルDQN（DDQN）
行動価値の推定が過大評価になることを防ぐために、

---

## 行動価値関数の評価と行動の選択に使用するNWを分けた手法

- 優先度付き経験再生

---

## 行動と報酬の記録から頻度の少ない行動や効果的と

---

## 思われる行動などを優先的に選んで学習を行う手法

---

## 深層強化学習とゲームAI

- デュエリングネットワーク
DQLではQ値のみを使用して学習を行うが、この手法では

---

## Q値を状態価値とアドバンテージに分けて学習を行う

- アドバンテージはQ値から状態価値を引いた値のこと
- カテゴリカルDQN

---

## 確率分布を活用することで効果的に学習を行う可能になった手法

---

## 深層強化学習とゲームAI

- Rainbow

---

## ダブルDQNや優先度付き経験再生など

---

## 様々な手法を組み合わせた手法

- 環境から獲得できる報酬とは別に、基準にもとづいて

---

## エージェント自身が生成する報酬である内発的報酬を改良した

- 難易度の高い様々なゲームで人間よりも高いスコアを叩き出した

---

## 深層強化学習とゲームAI

- Rainbowの後継モデル

---

## Rainbowを改良したモデルにAPE-Xがある

- 分散学習が可能なモデルであり効率的に学習を行える
- 1977年にアメリカのアタリ社が販売したゲームAtari 2600の

---

## 一部のミニゲームで人間のスコアの約4倍のスコアを叩き出した

- Agent57は「Atari 2600」の全ミニゲームで人間以上のスコア

---

## 深層強化学習とゲームAI

- AlphaGo

---

## DeepMind社が開発した囲碁のプログラム

- 人間のプロ棋士に勝利した

---

## モンテカルロ木探索と深層強化学習を組み合わせたもの

- モンテカルロ木探索

---

## モンテカルロ法を使った木探索のこと

---

## 深層強化学習とゲームAI

- AlphaGo Zero

---

## AlphaGoを発展させた囲碁プログラム

- 人間の棋譜データを使わずに深層強化学習を行った
- 人間の知識を使わずに0から学習、AlphaGoよりも強くなった

---

## 深層強化学習とゲームAI

- Alpha Zero

---

## 囲碁‧チェス‧将棋などボードゲームのトッププレイヤーに勝利

- 将棋やチェスなどの世界最高峰であったAIにも勝利し

---

## AlphaGo Zeroよりも強くなった

- 人間の棋譜データを使わずに自己対戦で学習を行った

---

## 深層強化学習とゲームAI

- マルチエージェント強化学習

---

## 複数エージェントがいる環境での強化学習のこと

- 100人が1人になるまでサバイバルするゲームの場合

---

## 99人の動きなどを考慮した上で行動する必要がある

- マルチエージェント強化学習の技術を
ゲームAIに持ち込むことで、ゲームAIの精度が上がった

---

## 深層強化学習とゲームAI

- マルチエージェント強化学習

---

## マルチエージェント強化学習を活用したゲームAIとして

---

## 以下2つが代表的なモデルになる

- OpenAI Five
- AlphaStar

---

## 深層強化学習とゲームAI

- OpenAI Five

---

## 対戦型リアルタイムストラテジーゲーム「Dota 2」の

---

## 2018年度世界大会覇者OGに勝利したモデル（OpenAIが開発）

- AlphaStar

---

## リアルタイムストラテジーゲーム「スタークラフト2」で

---

## トップレイヤーに勝利したモデル（DeepMind社が開発）

---

## 深層強化学習とゲームAI

---

## 深層強化学習分野

---

## 実システム制御への応用

作成者：辻 大貴
- 実システム制御への応用

---

## 深層強化学習を実世界で応用するときの課題が存在する

- 連続値制御問題
- 報酬設計に関する問題
- データ収集コストに関する問題
- 安全性の問題

---

## 実システム制御への応用

- 連続値制御問題

---

## どのように連続値を扱っていけばいいのかという問題のこと

- 強化学習では、離散値の状態や行動が扱われきた

---

## 実世界では進行角度など連続値を扱うため必要がある

- 連続値：切れ目なく連続している値のこと（速度、角度など）
- 離散値：連続していない値のこと（整数、人数など）

---

## 実システム制御への応用

- 連続値制御問題

---

## 実システム制御への応用

---

## モデル

---

## センサーデータ

---

## 離散値‧連続値連続値

---

## 行動情報

---

## ロボット

---

## 離散値連続値

- 連続値制御問題

---

## 連続値をコンピュータが理解できるように離散値に

---

## 変換していく必要があるが適当に離散値にしてしまうと

扱うべき状態‧行動が増えてしまい、学習が困難になってしまう
- 高次元になると生じる問題を次元の呪いという
- 高次元のデータをどのように処理するかが問題である

---

## 実システム制御への応用

- 次元の呪い
ディープニューラルネットワークを活用し、高次元のデータから
特徴を抽出し、強化学習を行っていくという手法が取られる
- 価値関数、方策などをNNを活用して近似することで、

---

## 高次元データを扱えるようにしている

- 状態に関する特徴表現学習を状態表現学習という

---

## 実システム制御への応用

- 報酬設計に関する問題

---

## 報酬関数の設計の出来によって方策は大きく変化してしまう

- 達成したい目標に合わせて報酬関数を設計する必要がある

---

## 不適切な報酬関数を設計すると達成したいタスクを

---

## 解くことができないという問題が発生してしまうことがある

- 適切な報酬関数を設計することを報酬成形という

---

## 実システム制御への応用

- データ収集コストに関する問題

---

## データを収集するためにはロボットを実際に動かす必要がある

- ロボットを高速で動かすことができないため時間がかかる
- ロボットは高価であるため大量に用意することは難しい

---

## 1件のデータを収集するのに時間がかかり収集コストが高くなる

---

## 実システム制御への応用

- 安全性の問題
方策を学習していく中で、エージェントは様々な行動を選択する
- 中には危険な行動を選択してしまう場合もある
- 高額なロボットが故障してしまったり、

---

## 人に危害を加えてしまったりする可能性がある

---

## 実システム制御への応用

- 課題に対する解決策

---

## ロボットなどに実施してほしいタスクに関する

---

## 情報（ドメイン知識）を事前に学習させる手法が提案

- オフラインデータの利用
- シミュレータの利用
- 残差強化学習
- 環境モデルの学習

---

## 実システム制御への応用

- オフラインデータの利用

---

## 強化学習ではデータを収集しながら方策を学習するが

---

## 実世界の場合データを収集しながら方策を学習するのは困難

- 時間的な問題で十分なデータを収集できない、

---

## 危険な操作により人や物に損害を与えてしまう など

- 事前に収集したデータ（オフラインデータ）で学習していく

---

## 実システム制御への応用

- オフラインデータの利用

---

## オフラインデータから方策を学習させていく手法として

---

## 模倣学習とオフライン強化学習がある

- 模倣学習

---

## 人間がロボットを操作して期待する行動を学習させる手法

- 期待する行動データをデモンストレーションという

---

## 実システム制御への応用

- オフライン強化学習

---

## オフラインデータを活用して強化学習を行う手法

- 模倣学習と異なり、与えられた情報をもとにして

---

## より精度の高い方策を学習しようとする

- 医療分野、自動運転分野で活用が期待されている

---

## 実システム制御への応用

- シミュレータの利用
ロボットを使用して解決したいタスクをシュミレータで再現し、

---

## シュミレータ上で方策を学習させる

- データ収集の効率などを上げ、収集コストを下げる効果がある
- シミュレータ

---

## 現実の環境を模擬的に再現したシステムのこと

---

## 実システム制御への応用

- sim2real（simulated-to-real）

---

## シミュレータで学習した方策を実世界に移転させること

- シミュレータと現実世界にはギャップ（リアリティギャップ）が
存在し、モデルの性能が低くなってしまう
- シミュレータで現実世界を表現しきることが難しい
- 対策としてドメインランダマイゼーションを活用する

---

## 実システム制御への応用

- ドメインランダマイゼーション
シミュレータの設定をランダムに変更することで、
様々な条件に対応することができる方策を作成し、

---

## シミュレータから実世界へ移行させたときの

---

## モデルの精度低下を防ごうとする手法のこと

- シュミレータと現実世界のギャップを小さくするための手法

---

## 実システム制御への応用

- 残差強化学習

---

## 従来型の制御システムの出力と最適な方策との

---

## 差分を強化学習で学習する手法

- 0から学習する必要がないためコストを低く抑えることができ、
予想外の行動をとる可能性が低いため、

---

## 安全面も高く有効な手法である

---

## 実システム制御への応用

- 環境モデルの学習
- 環境モデル

---

## 状態がどのように遷移するのかなどをモデル化したもの

- エージェントがある行動を選択後、別の状態に遷移する
確率などを使用して、エージェントに報酬や状態を渡す
- エージェントは状態や報酬を受け取り、学習を行っていく

---

## 実システム制御への応用

- 環境モデルの学習
- 環境モデル

---

## 実システム制御への応用

---

## エージェント

---

## 環境

---

## （環境モデル構築）

---

## 状態

---

## 行動

---

## 報酬

- モデルベース

---

## 環境モデルを使用するアルゴリズム

- モデルフリーの手法よりもサンプル効率が向上するとされる
- モデルフリー

---

## 環境モデルを使用しないアルゴリズム

---

## 実システム制御への応用

- モデルフリー

---

## 環境モデルを構築することが困難であるため

---

## 実用化されているほとんどのアルゴリズムがモデルフリーである

- 環境や状態に関するパラメータを推定することは非常に難しい

---

## 実システム制御への応用

- 環境モデルの学習
- 世界モデル

---

## エージェントを取り巻く環境のモデルを

---

## 観測によって得た情報を使って構築する枠組のこと

- イメージとして環境モデルを構築する枠組のことである
- エージェントが世界モデルを活用して学習を行っていく

---

## 実システム制御への応用

---

## データ生成①

作成者：辻 大貴
- 生成モデル

---

## 画像などの新しいデータを生成することを目的としたモデル

- 新しいデータを作り出すタスクを生成タスクと呼ぶ
- 識別モデル

---

## 画像などを分類‧識別することを目的としたモデル

- 犬や猫などに分類したり、人の顔を識別したりするモデル

---

## データ生成①

- 生成モデル

---

## データは何かしらの分布によって生成されていると仮定

- 元となるデータ（画像データなど）からデータ分布を学習し、

---

## その分布に従うようなデータを生成していく

---

## データ生成①

---

## X2

---

## X10

---

## X2

---

## X10

---

## ⻘のデータを

---

## 生成

- 画像生成の仕組み
訓練データである画像データから潜在空間を学習し、

---

## 潜在空間に基づいて新しい画像を生成する

- 潜在空間

---

## 学習させた画像の特徴量を分布させた空間のこと（高次元）

---

## データ生成①

- 深層生成モデル

---

## ディープラーニングを取り入れた生成モデルのこと

- ディープラーニングが登場する前から考え方は存在したが

---

## 複雑なデータを生成することは難しかった

- 変分オートエンコーダ（VAE）、

---

## 敵対的生成ネットワーク（GAN）が代表的なモデルになる

---

## データ生成①

- 変分オートエンコーダ（VAE）

---

## オートエンコーダを活用した深層生成モデル

---

## データ生成①

- 変分オートエンコーダ（VAE）

---

## 入力データを統計分布に変換（学習で行うこと）

- 統計分布に基づいて潜在変数（表現ベクトル）をサンプリング
- 潜在変数をもとに新しいデータを生成していく
- 潜在変数とは直接観測されていない計算によって求められた値
潜在変数は毎回異なるため、生成される画像も異なる

---

## データ生成①

---

## データ生成①

---

## 平均

---

## 分散

---

## 潜在変数

---

## エンコーダ

---

## デコーダ

---

## x

---

## y

- 変分オートエンコーダ（VAE）
変分オートエンコーダを発展させた手法として、
info-VAE、VQ-VAE、β-VAEなどがある
- info-VAE（Information Maximizing-VAE）

---

## 入力データと潜在変数の相互情報量を最大化するように学習

- 適切な潜在空間の学習が可能になり、生成精度が向上した

---

## データ生成①

- 変分オートエンコーダ（VAE）
- VQ-VAE（Vector Quantised-VAE）
潜在変数を最も近いコードブックから選択し、

---

## 選択された潜在変数を使用して画像を生成する手法

- 潜在変数を離散値にするという効果がある
- コードブックは学習によって求められたベクトルの集合

---

## データ生成①

- 変分オートエンコーダ（VAE）
- VQ-VAE（Vector Quantised-VAE）

---

## データ生成①

---

## ベクトルA = { 10, 8 , 4, 8, 2 }

---

## ベクトルB = { 2, 3 , 12, 9, 3 }

---

## ベクトルC = { 8, 5 , 3, 1, 10 }

- ‧‧‧

---

## コードブック

---

## 潜在変数 = { 7, 4 , 3, 4, 12}

---

## 潜在変数 = { 8, 5 , 3, 1, 10 }

- 変分オートエンコーダ（VAE）
- β-VAE

---

## 最適化関数にパラメータβを追加したモデルである

- βを追加することで、入力データの各特徴を適切に捉え、
各特徴を分離して、潜在空間を上手く表現することができる
- 生成精度を向上させることができるとされている

---

## データ生成①

- 敵対的生成ネットワーク（GAN）

---

## ジェネレータとディスクリミネータで構成される生成モデル

- ジェネレータ   ：ランダムなノイズを入力し、

---

## 新しい画像を生成するもの

- ディスクリミネータ：ジェネレータが生成した画像の

---

## 真偽を予測するもの

---

## データ生成①

---

## データ生成①

---

## ジェネレータディスクリミネータ

---

## 画像

---

## 真偽判定

- 敵対的生成ネットワーク（GAN）
ジェネレータとディスクリミネータで競い合わせて、

---

## より精度の高い画像を生成するモデルである

- ジェネレータはより精度の高い画像を生成できるように、

---

## ディスクリミネータは生成された画像を識別できるように学習

- イアン‧グッドフェローらによって提案された手法

---

## データ生成①

- DCGAN

---

## ジェネレータとディスクリミネータに

---

## 畳み込みニューラルネットワーク（CNN）を用いたモデル

- 精度の高い画像を生成することが可能である
- DCGANは「Deep Convolutional GAN」の略である

---

## データ生成①

- Pix2Pix

---

## 条件付き敵対的生成ネットワーク（CGAN）の1種

- 白黒画像からカラー画像を生成できたりする
- 様々なペアの画像を使って敵対生成学習を行う
- 画像Aと画像Bを用意し、画像Aにノイズを与え変換した画像を

---

## 画像Bに近づけるように学習を行っていく

---

## データ生成①

---

## データ生成①

---

## 画像Aジェネレータ

---

## ディス

---

## クリミネータ

---

## 画像A

---

## 変換画像

---

## 画像A

---

## 画像B

---

## ノイズ

- Cycle GAN

---

## 条件付き敵対的生成ネットワーク（CGAN）の1種

- 男性の写真を女性の写真に変更する など
元の画像を変換し、変換した画像を元の画像に再変換し、

---

## 再度変換した画像と元の画像が一致するように学習を行う

- 画像のペアが必要のないため、データを揃えるコストが低い

---

## データ生成①

---

## データ生成①

---

## 画像

---

## （ウマ）

---

## 変換画像

---

## （シマウマ）

---

## 再変換画像

---

## （ウマ）

---

## 同じようになるように学習

---

## データ生成②

作成者：辻 大貴
- 拡散モデル（Diffusion Model）
拡散過程と逆拡散過程の処理を繰り返し、

---

## 画像データを生成する手法のこと

- 多くの画像生成サービスの基本的な技術になっている
- 拡散過程 ：画像にノイズを加える処理
- 逆拡散過程：ノイズを取り除く処理

---

## データ生成②

- 拡散モデル（Diffusion Model）
- 一定のルールに従って画像にノイズを加えていく

---

## データ生成②

---

## 拡散過程

- 拡散モデル（Diffusion Model）
- 画像からノイズを取り除くモデルを使用してノイズを取り除く

---

## データ生成②

---

## 逆拡散過程

- 拡散モデル（Diffusion Model）

---

## 学習を繰り返すことでノイズ画像から

---

## 新しい画像を生成することが可能になる

- 大量のりんごの画像を学習させることで、

---

## 適当なノイズ画像から

---

## 新しいりんごの画像が生成される

---

## データ生成②

- NeRF
複数の視点からの2D画像データから３D構造を推測し、

---

## 3Dシーンを生成する手法‧技術のことである

- 立体的に物体の把握が可能（異なる視点から物体を把握）
- 3Dシーン

---

## 3Dデータを表示するための仮想的な空間のこと

---

## データ生成②

- NeRF

---

## データ生成②

---

## 生成モデルにおける

---

## 誤差関数

作成者：辻 大貴
- 生成モデル

---

## データは何かしらの分布によって生成されているという

仮定に基づいて、データの分布を学習し、

---

## 学習した分布（モデル分布）に基づいてデータを生成している

- データ分布とモデル分布の誤差が最小になるように

---

## 生成モデルの学習を行っていく

---

## 生成モデルにおける誤差関数

- 指標
データ分布とモデル分布の誤差の指標として、

---

## カルバック‧ライブラー情報量（KLダイバージェンス）と

---

## イェンゼン‧シャノン情報量（JSダイバージェンス）がある

- 変分オートエンコーダ（VAE）では

---

## 誤差関数にKLダイバージェンスが含まれている

---

## 生成モデルにおける誤差関数

- 指標

---

## 生成モデルにおける誤差関数

---

## マルチモーダルAIと

---

## 一気通貫学習

作成者：辻 大貴
- マルチモーダルAI

---

## 複数の入力データをもとに処理をするAIのこと

- 自動運転技術やロボット制御は代表的なマルチモーダルAI
物体検出や物体認識、速度、燃料の量、位置情報など

---

## 様々な情報をもとにAIが最適な処理を行っている

- 複数の入力データを処理する技術をマルチモーダル技術

---

## マルチモーダルAIと一気通貫学習

- マルチモーダル学習

---

## 様々な形式のデータを使って学習する手法のこと

- 一気通貫学習

---

## ロボットの一連の動作を1つのディープラーニング

---

## ネットワークで実現しようとする手法のこと

- 画像、センサーなどの情報から予測などを行いロボットを操作

---

## マルチモーダルAIと一気通貫学習

---

## テキストと画像

作成者：辻 大貴
- テキストと画像
近年ではテキストから画像を生成したり、

---

## 画像からテキストを生成したりするAIが数多く登場している

- テキストから画像に変換することをText-to-Image

---

## 画像からテキストに変換することをImage-to-Textという

---

## テキストと画像

- CLIP
画像検索、画像キャプション生成、VQAなど様々な

---

## タスクをこなすことができるモデル

- 画像とテキストのペアのデータを大量に学習させることで、

---

## モデル自らがペアの画像とテキストの各特徴を学習している

---

## テキストと画像

- VQA（Visual Question Answering）
画像とその画像に関する質問を受け取って、

---

## 正しい答えを出力するタスクのこと

- 猫が複数写っている画像と猫が何匹いるかという質問を
入力すると、猫の数が出力される

---

## テキストと画像

- CLIP
学習していないクラスに対して、文章などで補足情報を与えると

---

## 適切にクラス分類などを行うことが可能（Zero Shot Learning）

- 最新のiPhoneの学習を行っていないモデルに、
最新のiPhoneの特徴（見た目）をテキスト情報で与え、

---

## 最新のiPhoneの画像を入力すると適切にクラスに分類される

---

## テキストと画像

- CLIP
学習していないタスクに対しても、Zero Shot Learningが可能
- VQAを学習していないモデルに、VQAの説明を与えると

---

## VQAを行うことができるようになる

---

## テキストと画像

- CLIP

---

## 大量のデータを学習することでテキストと画像との

関連性を適切に捉えることができているため、

---

## Zero Shot Learningが可能である

- Flamingo、Unified-IOなどのモデルも登場してきた

---

## テキストと画像

- Flamingo
イギリスにあるDeepMind社が開発したモデルで、

---

## CLIPをベースに開発されている

- Unified-IO

---

## アメリカにある非営利人工知能研究所であるAI2によって

開発されたモデルで、様々なタスクを実行することが可能

---

## テキストと画像

- Dall-E
CLIPと拡散モデル( Diffusion Model )を用いたモデルで、

---

## テキスト情報から画像を生成することができる

- 大規模なデータセットで事前学習（上流タスク）され

---

## ファインチューニングなどで翻訳やVQAのような

---

## 特化タスク（下流タスク）に適応できるモデルを基盤モデル

---

## テキストと画像

---

## モデルの解釈性の問題と

---

## その対応

作成者：辻 大貴
- ブラックボックス問題
AIによって出力された結果が、どのようなプロセスで

---

## 導き出されたのか分からないという問題のこと

- AIによって出力された結果に対して根拠がないと不安

---

## 「〇〇が陽性」とAIが判断しても医師は正しく説明できない

- ブラックボックス問題を解決するための研究が進められる

---

## モデルの解釈性の問題とその対応

- モデルの解釈

---

## モデルが複雑になればなるほど根拠は分かりにくくなる

- 特定の特徴量などから局所的に判断の根拠を推定する
- LIME、SHAP、Permutation Importanceなどの手法がある
- モデル全体から判断の根拠を推定
- 画像分野ではCAMなどの手法が考えられる

---

## モデルの解釈性の問題とその対応

- LIME
複雑なモデルの予測に近似する単純な線形回帰を作成し、

---

## どの特徴量が推論に影響を与えたのかを算出する手法

- SHAP
ゲーム理論におけるShapley値を利用して、

---

## 各特徴量が予測にどの程度影響を与えたかを算出する手法

---

## モデルの解釈性の問題とその対応

- Permutation Importance
入力データの特徴量の値を入れ替え、モデルに入力
- 予測精度のズレから、各特徴量の影響度を把握する手法

---

## モデルの解釈性の問題とその対応

---

## 家賃距離地域災害

---

## 10万800mA区中

---

## 20万150mA区中

---

## 13万800mB区高

---

## 家賃距離地域災害

---

## 10万800mB区中

---

## 20万800mA区中

---

## 13万150mA区高

---

## 入れ替え

- CAM

---

## CNNが画像のどの部分を見て判断しているのかを

---

## 可視化する手法のことである

- CAMはGAP層の前の特徴マップとネットワークの重みを利用し、

---

## 画像のどの部分を見て判断しているのかを可視化している

- 全結合層の代わりに特徴マップの平均値を使用する層

---

## モデルの解釈性の問題とその対応

- CAM

---

## モデルの解釈性の問題とその対応

---

## 画像

---

## 畳

---

## み

---

## 込

---

## み

---

## 層

---

## プ

｜

---

## リ

---

## ン

---

## グ

---

## 層

---

## 特徴

---

## マップ

---

## 特徴

---

## マップ

---

## 特徴

---

## マップ

---

## 画

---

## 素

---

## を

---

## 並

---

## べ

---

## る

---

## 畳

---

## み

---

## 込

---

## み

---

## 層

---

## プ

｜

---

## リ

---

## ン

---

## グ

---

## 層

---

## G

---

## A

---

## P

---

## 層

---

## 出

---

## 力

---

## 層

---

## モデルの解釈性の問題とその対応

---

## GAP層

---

## 特徴

---

## マップ

---

## 特徴

---

## マップ

---

## 特徴

---

## マップ

---

## クラスA

---

## クラスB

---

## 重み

---

## 出力層

---

## モデルの解釈性の問題とその対応

---

## GAP層

---

## 出力層

---

## 特徴

---

## マップ

---

## 特徴

---

## マップ

---

## 特徴

---

## マップ

---

## クラスA

---

## クラスB

---

## 重み

- Grad-CAM

---

## CAMはネットワークに制約があり使用できない場合があった

- CAMを改良したGrad-CAMが登場した（勾配を利用）
- CNNが画像を判断するときに重要視している箇所を
ヒートマップで表示され、人が判断の根拠を推定していく
- 勾配が大きいと重要視していると考えられる

---

## モデルの解釈性の問題とその対応

- Grad-CAM

---

## モデルの解釈性の問題とその対応

- Guided Grad-CAM

---

## より詳細にどういった特徴を抽出しているのか可視化

- Grad-CAMとGuidedBackPropagationを組み合わせた手法
- GuidedBackPropagation
出力から入力にたどって、重要視した特徴を抽出する方法
- BackPropagationは誤差逆伝播法という意味である

---

## モデルの解釈性の問題とその対応

---

## モデルの軽量化

作成者：辻 大貴
- エッジAI

---

## 学習したAIをエッジデバイスに搭載したもの

- 車（自動運転）、製造ロボット などで使われることが期待

---

## エッジデバイスで推論などを行うという特徴がある

- エッジデバイス

---

## インターネットに接続された端末のこと

---

## モデルの軽量化

- クラウドAI

---

## クラウド上で学習や推論を行うAIのこと

- データの送信‧推論結果の受信を行うため遅延が発生

---

## リアルタイムで推論したい場合には向かない

- 大規模で複雑な処理（推論）を行うことができる
- クラウドとはネットワーク経由でサービスを提供する形態

---

## モデルの軽量化

---

## モデルの軽量化

---

## クラウドAIエッジAI

---

## 推論の結果学習用データ学習モデル

---

## 学習用データ

---

## (必要な場合)

---

## 学習‧推論学習

---

## 推論

---

## （学習）

- モデル圧縮の手法

---

## 学習済みモデルをスマホ端末などの機器に搭載する場合

大規模なモデルだと計算量が多くなり、

---

## 処理能力が限界になるためモデルの軽量化が必要になる

- モデルを軽量化（モデル圧縮）する代表的な手法は
蒸留、量子化、プルーニング がある

---

## モデルの軽量化

- 蒸留

---

## 学習済みモデルの入力と出力を学習させ

---

## 小さなモデルを作成する手法のこと

- 既存モデルの構造が分からない場合でも似た結果を

---

## 出力するモデルを作成することができる（蒸留モデル）

- 学習済みモデルを教師モデル、新しいモデルを生徒モデル

---

## モデルの軽量化

- 蒸留

---

## モデルの軽量化

---

## 教師モデル

---

## 生徒モデル

---

## 入力出力

---

## 学習学習

- 蒸留

---

## 一般に教師モデルが学習時に使用する正解ラベルはhard target

- 動物を識別するモデルの場合、犬の画像を入力したとき、

---

## 正解ラベルは犬になる（１つの正解が存在する）

- 生徒モデルが学習時に使用する正解ラベルはsoft target

---

## 教師モデルが出力時に使用する各クラスの確率分布を使用する

---

## モデルの軽量化

- 特定のデータを入力した結果、算出された確率を事後確率

---

## 生徒モデルは教師モデルの事後確率を正解ラベルとして使用

- 教師モデルを教師ネットワーク、生徒モデルを生徒ネットワーク

---

## モデルの軽量化

---

## 教師モデル生徒モデル

クラスA：80%
クラスB：15%
クラスC：10%
クラスD：  5%
- 量子化

---

## 重みなどのパラメータを小さいビットで表現し

---

## モデルを軽量化させる方法

- 全体のメモリ使用量や計算量を削減することができる
- 32ビット⻑の変数を8ビット⻑の変数に置き換えることで
計算量は4分の1になるが、モデルの精度が低くなってしまう

---

## モデルの軽量化

- 量子化
32ビット：連続した32個（桁）のビット
8ビット  ：連続した8個（桁）のビット
- ビット
情報の最小単位のこと、コンピュータでは0または1が対応
- 8ビットならば01001101のように8桁のビットを意味する

---

## モデルの軽量化

- プルーニング

---

## ニューラルネットワークのユニットの中で

重みが小さい接続を削除して、パラメータ数を減らすこと
- 重要度の低いユニット同士の結合を削除していくこと
- パラメータを少なくすることで計算量を減らせるが、

---

## 精度が落ちてしまうデメリットも存在する

---

## モデルの軽量化

- プルーニング

---

## モデルの軽量化

- プルーニング

---

## 接続を切った後は調整するためモデルを学習させる

- モデルを再学習させるとき、重みの値を初期値にしている
従来は、接続を切る前の重みの値を使用して再学習していた
- 重みを維持して学習させるよりも初期値にする方が

---

## モデルの精度が高くなるとされている

---

## モデルの軽量化

- プルーニング

---

## プルーニングは枝切りとも呼ばれている

- 重みが小さい接続を切っていくマグニチュードベース

---

## 勾配情報などを利用して接続を切っていく勾配ベースがある

---

## モデルの軽量化

- 宝くじ仮説
大規模なニューラルネットワークの中には、

---

## 性能がほとんど変わらない小さなニューラルネットワークが

---

## 存在するという仮説のことである

- 場合によっては２０％以下のサイズになることもある
- 小さなニューラルネットワークをサブネットワークという

---

## モデルの軽量化

---

